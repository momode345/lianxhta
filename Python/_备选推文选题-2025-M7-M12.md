
# 论文推介

Aguilar-Loyo, J. (2025). A comparative analysis of two-way fixed effects estimators in staggered treatment designs. Journal of Econometrics, 251, 106059. [Link](https://doi.org/10.1016/j.jeconom.2025.106059), [PDF](https://github.com/arlionn/lianxhta/blob/main/PDF/Aguilar-Loyo-2025-JoE-TWFE.pdf), [Google](<https://scholar.google.com/scholar?q=A comparative analysis of two-way fixed effects estimators in staggered treatment designs>).


# R10：每日大牛-

按照小红书的风格写一篇推文，介绍 Google 公司的 Addy Osmani。

Addy Osmani is a Software Engineer at Google working on Chrome and AI.

- Website: <https://addyosmani.com>
- Github: <https://github.com/addyosmani>

![github-stars-Osmani](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/github-stars-Osmani.png)

Engineering leader and senior thinker
Addy Osmani is an Irish [Software Engineer](https://www.linkedin.com/in/addyosmani/) and leader currently working on the [Google Chrome](https://www.google.com/chrome/) web browser and [Gemini](https://gemini.addy.ie/) with [Google DeepMind](https://deepmind.google/). A developer for 25+ years, he has [worked](https://addyosmani.com/bio/) at Google for over thirteen years, focused on making the web [low-friction](https://blog.chromium.org/2018/09/10-years-of-speed-in-chrome_11.html) for users and web developers. He is passionate about AI-assisted engineering and developer tools. He [previously](https://golden.com/wiki/Addy_Osmani_(software_engineer)-REKEB86) worked on Fortune 500 sites. Addy is the [author](https://g.co/kgs/t9AVE7) of a number of [books](https://store.addy.ie/) including [Learning JavaScript Design Patterns](https://www.oreilly.com/library/view/learning-javascript-design/9781449334840/), [Leading Effective Engineering Teams](https://leet.addy.ie/), [Stoic Mind](https://stoic.im/) and [Image Optimization](https://www.smashingmagazine.com/printed-books/image-optimization/). You can try his recent [apps](https://apps.addy.ie/).You can find him on [LinkedIn](https://www.linkedin.com/in/addyosmani), [Twitter](https://twitter.com/addyosmani) or [TikTok](https://tiktok.com/@vvoicemotivation). He's given over 175 [talks](https://www.youtube.com/playlist?list=PLVUliVBcvz1lKS9-rcPFFXkwGOj_YX_-5) worldwide. You can find Addy's writing on his [blog](https://addyosmani.com/blog/), [Substack](https://substack.com/@addyosmani) and on [LeadDev](https://leaddev.com/community/addy-osmani).

## 16 岁成名

- <https://addyosmani.com/bio/>

![AddyOsmani-with-award-2.jpg](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/AddyOsmani-with-award-2.jpg)

## xss

![20251015230453](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20251015230453.png)


# R09-每日大牛：Andrej Karpathy

- https://karpathy.ai/
- https://en.wikipedia.org/wiki/Andrej_Karpathy
- https://github.com/karpathy
- https://cs.stanford.edu/people/karpathy/

Building[@EurekaLabsAI](https://x.com/EurekaLabsAI)
. Previously Director of AI @ Tesla, founding team @ OpenAI, CS231n/PhD @ Stanford. I like to train large deep neural nets.

# Stata Coding Practices: Debugging

写一篇推文，介绍 Stata 中如何排查各种错误信息。主要涵盖的主题括：

- 错误信息的分类：`help error`
- `set trace on` 和 `set trace off` 的用法
- 常见错误
  - 路径问题
  - 命令无法识别
  - 变量不存在
  - 选项填写错误
  - 数据类型不匹配
- 如何借助 AI 工具（如 ChatGPT）排查 Stata 错误
  - 你需要发给 AI 的信息
  - 如何描述你的问题
  - 提示词的撰写

参考资料：

- [A note on debugging in Stata](http://www.econometricsbysimulation.com/2012/06/note-on-debugging-in-stata.html)
- Avnish95, 2021, Blog. [Stata Coding Practices: Debugging](https://dimewiki.worldbank.org/Stata_Coding_Practices%3A_Debugging)
- Shannon Driver, Stata FAQs. [How do I debug my program?](https://www.stata.com/support/faqs/programming/debugging-program/)
- [Debugging Stata](https://labordynamicsinstitute.github.io/ldilab-manual/96-05-debugging-stata.html)
- Assessing ChatGPT's Ability to Detect and Correct
Programming Errors in Stata Do-Files*Ricardo Mora, February 2025. [-PDF-](https://e-archivo.uc3m.es/rest/api/core/bitstreams/5cba974a-cebc-488f-9eb1-91c3f0839c68/content)

# Stata初学者必读：安装和路径设定问题

- 主要参考这篇文章的思路和结构：[Sebastian’s way of setting up STATA Folder Structure](https://sebastiantellotrillo.com/resources/sebastians-way-of-setting-up-stata-folder-structure)

- 目的：主要介绍 Stata 中的路径设定问题，涵盖以下内容：

- 重要：
  - **安装路径要简洁干净**：安装 Stata 时，务必避免安装路径中包含中文字符或空格，否则可能导致各种问题。建议直接安装在根目录下，如 `C:/Stata17` 或 `D:/Stata17`。
    - 然后你可以另设一个不同于安装路径的文件夹，如 `D:/mystata`，用于存放个人文件 (`PERSONAL`) 和外部命令 (`PLUS`)。这样做的好处是，无论随后是否升级 Stata 版本，你的个人文件和外部命令都不会丢失，也不需要迁移。
  - **许可证**：确保你有合法的 Stata 许可证，并正确激活 Stata 软件。许可证问题可能导致无法使用某些功能或命令。尤其是在 VScode 中使用 Stata 时，务必确保 Stata 已正确激活，否则会出现无法识别命令的错误。

后续内容安排：

- 绝对路径和相对路径的区别
- 系统路径查看和设定
   详情参见 [**[P]** sysdir](https://www.stata.com/manuals/psysdir.pdf)
  - `sysdir` 命令，
  - `sysdir set` 命令
  - 写入 `profile.do` 文件
  - 完成上述设定后，当你执行 `ssc install` 或 `net install` 安装外部命令时， 
- 如何查看和设置当前工作目录
  - `cd` 命令
  - `pwd` 命令
- 文档结构的设定
  - `do` 文件头部的路径设定
  - 参见如下推文：

## 参考资料
- 张弛, 2024, [Stata代码规范指南](https://www.lianxh.cn/details/1452.html).
- 汪京, 2024, [Stata代码规范指南](https://www.lianxh.cn/details/1377.html).
- 李青塬, 2025, [优雅的实证研究：文档结构与基本规则](https://www.lianxh.cn/details/1633.html).


# Stata 中的常用设定

- [Stata: Common Settings](https://www.stata.com/support/faqs/programming/common-settings/)

## set 系列命令

- `set` 系列命令：主要介绍 `set more off`, `set seed #`, `set trace on/off`, `set type double`, `set showbaselevels`, `set cformat` 等常用命令的作用和使用场景。
  - 有关 `set` 命令的完整介绍，参见 [**[R]** set](https://www.stata.com/manuals/rset.pdf)。
  - TechTips, 2024. [Common Stata settings using the set command](https://www.techtips.surveydesign.com.au/post/common-stata-settings-using-the-set-command). [-PDF-](https://www.techtips.surveydesign.com.au/post/common-stata-settings-using-the-set-command)
  - 说明：对于一些需要长期使用的设置，可以将这些 `set` 命令写入 `profile.do` 文件中，这样每次启动 Stata 时都会自动执行这些设置。
    - 详见：连玉君, 2020, [Stata：聊聊 profile.do 文件](https://www.lianxh.cn/details/77.html).

## sysdir set 系列命令

- `sysdir set` 系列命令：主要介绍 `sysdir set PERSONAL`, `sysdir set ADO`, `sysdir set BASE` 等命令的作用和使用场景。
  - 有关 `sysdir` 命令的完整介绍，参见 [**[P]** sysdir](https://www.stata.com/manuals/psysdir.pdf)。
  - 说明：对于一些需要长期使用的设置，可以将这些 `sysdir set` 命令写入 `profile.do` 文件中，这样每次启动 Stata 时都会自动执行这些设置。
    - 详见：连玉君, 2020, [Stata：聊聊 profile.do 文件](https://www.lianxh.cn/details/77.html).

https://www.techtips.surveydesign.com.au/post/common-stata-settings-using-the-set-command


# 从哪里找数据？

- AEA：[Data Resources for Economists](https://www.aeaweb.org/about-aea/committees/economic-statistics/data-resources)
- [Primer: Where to find data](https://sebastiantellotrillo.com/resources/primer-where-to-find-data)
- [Our World in Data](https://ourworldindata.org/)
- [Open ICPSR](https://www.openicpsr.org/)
- General data
  - [Google Dataset Search](https://datasetsearch.research.google.com/)
  - [Kaggle Datasets](https://www.kaggle.com/datasets)
  - [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)
  - [Data.gov](https://www.data.gov/)
  - [FiveThirtyEight Data](https://data.fivethirtyeight.com/)
  - [Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets)


- 专项数据
  - [世界银行数据](https://data.worldbank.org/)
  - [Public Use Data Archive | NBER](https://www.nber.org/research/data)
  

# JFE, JF, RFS 主编们的联合建议

将这份建议翻译成中文，加上「编者按」，强调这份声明也适于其他 Top Journals（AER, QJE, Econometrica, REStat, JASA, JRSS-B 等），并推荐给大家阅读。

- [2020 版建议](https://www.billschwert.com/jfe/jointed13.pdf)，[HTML 格式](https://www.billschwert.com/jfe/jointed13.htm)

---

《给作者的建议》核心要点梳理
一、背景与目的

背景：2002年《金融经济学杂志》（JFE）、《金融杂志》（JF）和《金融研究评论》（RFS）联合发表社论，呼吁作者重视审稿人意见；2025年因观察到不良投稿现象， editors决定重申该建议。
核心目的：强调同行评审机制中审稿人时间的稀缺性，呼吁作者尊重审稿反馈，提升投稿质量和评审效率。

二、批评的两种不良投稿行为


过早投稿，依赖审稿人完善论文

表现：作者在论文未成熟阶段投稿，期望“通过审稿人意见指导修改”。
后果：加重审稿人负担，且因论文质量不足被拒概率高，可能永久失去优质期刊发表机会。



无视审稿反馈，直接转投其他期刊

表现：收到拒稿后，未根据审稿意见修改，直接将原文投往其他期刊。
后果：

跨期刊审稿人可能重叠，审稿人发现作者未采纳建议时，会对作者态度产生负面评价；
传递“作者将评审视为随机筛选，而非改进机会”的信号，降低后续评审的合作意愿。





三、给作者的核心建议


投稿前：充分打磨论文

确保论文达到“有较高录用可能性”的质量标准后再投稿，避免将审稿人视为“免费顾问”。



收到反馈后：认真回应并修改

即使不同意审稿意见，也应基于反馈反思论文缺陷；转投前必须修改，体现对评审意见的尊重。



理性看待拒稿与评审局限性

承认评审机制可能存在疏漏（如草率或有偏见的审稿），但应相信多数审稿人是认真负责的，其意见有助于提升论文质量。



四、强调评审生态的重要性

审稿人贡献的价值：审稿人无偿提供时间、专业知识和创意，是学术共同体的核心资源。
作者行为的影响：作者对审稿意见的态度直接影响审稿人积极性，进而影响整个学术评审生态的可持续性。

五、补充说明

历史文献：2002年联合社论原文可通过链接下载PDF（Richard Green, Maureen O'Hara, and G. William Schwert, "Joint editorial: Advice for authors"）。

总结：文章核心是呼吁作者以“合作而非对抗”的态度参与学术评审，通过尊重审稿人劳动、重视反馈修改，共同维护高效、建设性的学术出版生态。


# 论文推介：Judge IV

- Chyn, E., Frandsen, B., & Leslie, E. (2025). Examiner and Judge Designs in Economics: A Practitioner’s Guide. Journal of Economic Literature, 63(2), 401–439. [Link](https://doi.org/10.1257/jel.20241719) (rep), [PDF](http://sci-hub.ren/10.1257/jel.20241719), [Appendix](https://www.aeaweb.org/doi/10.1257/jel.20241719.appx), [Google](<https://scholar.google.com/scholar?q=Examiner and Judge Designs in Economics: A Practitioner’s Guide>). [-Replication-](https://doi.org/10.3886/E209883V1) 

  -This article provides empirical researchers with an introduction and guide to research designs based on variation in judge and examiner tendencies to administer treatments or other interventions. We review the basic theory behind this research design, outline the assumptions under which the design identifies causal effects, describe empirical tests of the conditions for identification, and discuss trade-offs associated with choices researchers must make for estimation. We demonstrate concepts and best practices in an empirical case study that uses an examiner tendency research design to study the effects of pretrial detention.

# fejiv：Fixed effect jackknife IV (FEJIV) estimation

```stata
help fejiv
```

## 参考文献

- Chao, J. C., Swanson, N. R., & Woutersen, T. (2023). Jackknife estimation of a cluster-sample IV regression model with many weak instruments. Journal of Econometrics, 235(2), 1747–1769. [Link](https://doi.org/10.1016/j.jeconom.2022.12.011), [PDF](https://eller.arizona.edu/sites/default/files/Jackknife%20estimation%20of%20a%20cluster%20sample%20IV%20%20many%20weak%20instruments%20Chao%20Swanson%20Woutersen%202023.pdf), [-PDF2-](), [Google](<https://scholar.google.com/scholar?q=Jackknife estimation of a cluster-sample IV regression model with many weak instruments>).
- Słoczyński, T. (2024). When Should We (Not) Interpret Linear IV Estimands as LATE? (Version 7). arXiv. [Link](https://doi.org/10.48550/arXiv.2011.06695) (rep), [PDF](https://arxiv.org/pdf/2011.06695.pdf), [Google](<https://scholar.google.com/scholar?q=When Should We (Not) Interpret Linear IV Estimands as LATE? (Version 7)>).
- Frandsen, B., Leslie, E., & Mcintyre, S. (2025). Cluster Jackknife Instrumental Variables Estimation. Review of Economics and Statistics, 1–19. [Link](https://doi.org/10.1162/rest.a.263), [Google](<https://scholar.google.com/scholar?q=Cluster Jackknife Instrumental Variables Estimation>).

# Tracking the Evolution of China’s Surface Transport Network

- *Steven J. Davis,† Meijun Qian‡, and Wen Zeng§11 August 2025, [-PDF-](https://static1.squarespace.com/static/5e2ea3a8097ed30c779bd707/t/68b23e5bcadf255abd0bc59e/1756511835388/Tracking+the+Evolution+of+China%27s+Surface+Transport+Network%2C+with+ack.pdf)

![20251005000443](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20251005000443.png)

# Python 环境配置指南

比如，解释如下语句的作用和构造方法，以及使用方法

```python
pip install -r requirements.txt
```

# AI 简史
结合如下推文，并使用 ChatGPT 补充 2022 年以后的分析。当然，你也可以酌情查阅资料进行补充和完善。 

- Tim Mucci, IBM, 2025. [The history of AI](https://www.ibm.com/think/topics/history-of-artificial-intelligence)
- [The History of Artificial Intelligence, Machine Learning and Deep Learning](https://www.algotive.ai/blog/the-history-of-artificial-intelligence-machine-learning-and-deep-learning)

# ModernBERT

Warner, B., Chaffin, A., Clavié, B., Weller, O., Hallstr?m, O., Taghadouini, S., Gallagher, A., Biswas, R., Ladhak, F., Aarsen, T., Cooper, N., Adams, G., Howard, J., & Poli, I. (2024). Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2412.13663) (rep), [PDF](https://arxiv.org/pdf/2412.13663.pdf), [Google](<https://scholar.google.com/scholar?q=Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference (Version 2)>). [Models](https://arxiv.org/abs/2412.13663)

- github: <https://github.com/AnswerDotAI/ModernBERT>
- [ModernBERT-base](https://huggingface.co/answerdotai/ModernBERT-base)
- [ModernBERT-large](https://huggingface.co/answerdotai/ModernBERT-large)

# ChronoBERT and ChronoGPT

He, S., Lv, L., Manela, A., & Wu, J. (2025). Chronologically Consistent Large Language Models (Version 3). arXiv. [Link](https://doi.org/10.48550/arXiv.2502.21206) (rep), [PDF](https://arxiv.org/pdf/2502.21206.pdf), [Google](<https://scholar.google.com/scholar?q=Chronologically Consistent Large Language Models (Version 3)>).

- `ChronoBERT` and `ChronoGPT` models publicly available at: <https://huggingface.co/manelalab>.
- Large language models are increasingly used in social sciences, but their training data can introduce lookahead bias and training leakage. A good chronologically consistent language model requires efficient use of training data to maintain accuracy despite time-restricted data. Here, we overcome this challenge by training a suite of chronologically consistent large language models, ChronoBERT and ChronoGPT, which incorporate only the text data that would have been available at each point in time. Despite this strict temporal constraint, our models achieve strong performance on natural language processing benchmarks, outperforming or matching widely used models (e.g., BERT), and remain competitive with larger open-weight models. Lookahead bias is model and application-specific because even if a chronologically consistent language model has poorer language comprehension, a regression or prediction model applied on top of the language model can compensate. In an asset pricing application predicting next-day stock returns from financial news, we find that ChronoBERT and ChronoGPT's real-time outputs achieve Sharpe ratios comparable to a much larger Llama model, indicating that lookahead bias is modest. Our results demonstrate a scalable, practical framework to mitigate training leakage, ensuring more credible backtests and predictions across finance and other social science domains.


# Hamiltonian Monte Carlo

- Python package: `NumPyro`, <a href="https://num.pyro.ai/en/stable/">https://num.pyro.ai/en/stable/</a>

# 模型中包含 AI/ML 生成的变量时的统计推断

- Battaglia, L., Christensen, T., Hansen, S., & Sacher, S. (2024). Inference for Regression with Variables Generated by AI or Machine Learning (Version 5). arXiv. [Link](https://doi.org/10.48550/arXiv.2402.15585) (rep), [PDF](https://arxiv.org/pdf/2402.15585.pdf), [Google](<https://scholar.google.com/scholar?q=Inference for Regression with Variables Generated by AI or Machine Learning (Version 5)>).
  - Codes to implement these bias corrections and standard error formulas are available in
the Python package `ValidMLInference`.

When performing inference for regression where covariates (independent variables) are generated or estimated using AI or machine learning methods, directly treating these AI/ML-generated variables as if they were observed data can lead to biased estimates and invalid inference. This is because the estimation process of these variables introduces measurement error or uncertainty that needs to be accounted for.

The Problem:

-   **Measurement Error:** 
    AI/ML models, while powerful, introduce a form of measurement error when estimating latent variables or complex features. This error, if ignored, can bias the coefficients of the downstream regression model.

-   **Invalid Confidence Intervals:** 
    Naively performing inference (e.g., calculating standard errors and confidence intervals) without accounting for the uncertainty in the AI/ML-generated variables will yield confidence intervals that are too narrow and thus invalid.

Solutions for Valid Inference:

Researchers have proposed methods to address this issue and obtain valid inference:

-   **Explicit Bias Correction:** 
    This involves estimating and correcting for the bias introduced by the AI/ML-generated variables. Bias-corrected confidence intervals can then be constructed.

-   **Joint Estimation:** 
    This approach involves jointly estimating the parameters of the regression model and the latent variables generated by the AI/ML method, often using maximum likelihood estimation. This allows the uncertainty in the generated variables to be incorporated directly into the estimation of the regression parameters.

Examples and Resources:

-   The paper "Inference for Regression with Variables Generated by AI or Machine Learning" by Hansen et al. (2025) provides a comprehensive theoretical and empirical analysis of this problem and proposes the two methods described above. This paper is available on platforms like arXiv and from institutions such as Yale University's Cowles Foundation.
-   While a specific GitHub repository for the Hansen et al. paper might not be immediately apparent, the concepts discussed are relevant to various projects dealing with causal inference and the integration of ML-generated features into statistical models. Libraries like `DoWhy` (a Python library for causal inference) or packages designed for handling measurement error in regression could offer relevant functionalities or examples for implementing these concepts.

**Key takeaway**: When using AI/ML-generated variables in a regression, it is crucial to recognize and address the potential for biased estimates and invalid inference by employing appropriate statistical methods like bias correction or joint estimation.

# 论文推介：生成式AI 

Eisfeldt, A. L., & Schubert, G. (2025). Generative AI and Finance. Annual Review of Financial Economics. [Link](https://doi.org/10.1146/annurev-financial-112923-020503), [PDF](https://download.ssrn.com/2025/1/29/4988553.pdf?response-content-disposition=inline&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGAaCXVzLWVhc3QtMSJHMEUCIQDaLdHgnKy9SaK9POYvicRMsnMIjhX06of8Aj5PlSVZpQIgVP110nW5%2FTKamdbtbTSSRvnlYNnZWq3GWPRUfO4y3T0qxgUI6f%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAEGgwzMDg0NzUzMDEyNTciDFBLbJz0yVlXrP19dCqaBZybSPs5xt%2FFaDeGBkCTu99Z6rw0ld5H%2FsrhAvOhA3Fv%2F9cr2Nj1OxbfEndAbwNBF1zIPJFbfzp30TecvsHeK0YzVHPE6tvxgZZKJ1mV4kRJvPaRW33hWuJs%2BbfYF9KfgOI3MAVRvWE5oJrGIzoDJUS6ugcc0U4peWrcDG81WFurwrAOapv5UjGRA6scQb2qHWU5Nt%2BM36PCMohdY2m1XmzWusrFL8isieAGEP4zBSm4gzb0rGqv7yuGJ2puuy43F9FF%2BaxYg88VR6NdCZftBfYANVcWVJdQk2HP%2Fnu%2BXZKw8LwmMl%2FX99w2j%2BWCXJFHSDmRChp0%2BLEs11x%2FprRd5jnk4OJ7EGMckv6y8g0aP3oApMuyLdYyNwYxqG%2BL0L0v7dtF%2BxHiDxbIR%2Fy%2FZOqv9vPcxUNATmM4POlC1JwPuBFRJVuAXslqdksmMU5R%2F8BdCeTv5%2F8dC%2F11yEXLCs9OxXlapqUdoC%2BrcySbPT6SFetkGOrLquQRcb%2FCDz62Yr%2F2SSd2qYyr98r%2F8AEl7g8%2FnsNVDFNTyCsVoNn33i%2FlGpVInz1Q441u6s7S9Rc%2B%2BsyjASUiWg%2BTCvd895s54Ie1K%2BLTJ5TabRDHKWlPoW71En1uus%2FGm%2BzyL80oxX1sT3YrKvonyclqSISvnbnq5sz2R3d7qa%2F%2Bj%2F0guHs4CzNQsmYeKlDfMgE0AUsDLUD%2F4l9Kq77iTmUWrpXZY5jvc6H9XhGP8OVXo6HiV%2BHy0ekaDoB5Ifo5Sqqp%2Bvbuw7BucrXvkzQLSrrl3wb85T7DcyLnJ6gnxoiJnmksERrJwwFQpbnfFHBr%2BjFGIpbtgpFaIQV6CyCDnAauOUdb5hqml9jf1PsVtITcXG0mUvbE6LEZBwCJX8MB%2FsZxwMryLDDxk%2B7GBjqxAUa21jUkC%2Bg1JgThAPTsGpQVMbLAlVAHUYr1CJ%2FUVXWn6hEZWYtyrcYhcOBRBuwJGJfYbBFD0auco07iYUO82oAG85Q7Xn3MPMEaSIaG1BmPKlnrjwPDEReeVmE%2FbINuI%2FUsb8VJ9qte4WRGlguxmaxpqgaFzOCELxW7xK8TkRomalmyDYWvA6cJFoGNHRoXllZ2%2BCnf0MWWv3Lw9Pa%2FZYm7K7r5TMfcRSIdTrwGQnIF2g%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250930T082002Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAUPUUPRWEXZ4LYADP%2F20250930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=784fecf879cdc5731861520481555f8b93b29442ec0e79dc32a1580fd95652b1&abstractId=4988553), [Google](<https://scholar.google.com/scholar?q=Generative AI and Finance>).

# 翻译：文本分析的开源工具-Python

- Open source Tools for Text as Data / NLP in Python, [-Link-](https://burtmonroe.github.io/TextAsDataCourse/Notes/PythonText/), [github](https://github.com/burtmonroe/TextAsDataCourse)

# 新书推荐：动手学深度学习

![front](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/front.png)

- website: <https://zh.d2l.ai/>
- PDF 版本：<https://zh-v2.d2l.ai/d2l-zh-pytorch.pdf>
- github: <https://github.com/d2l-ai/d2l-zh>

![20250929102633](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250929102633.png)

## 内容和结构

全书大致可分为三个部分，在 图 1 中用不同的颜色呈现：
![20250929102853](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250929102853.png)

- 第一部分包括基础知识和预备知识。1节提供深度学习的入门课程。然后在 2 节中，我们将快速介绍实践深度学习所需的前提条件，例如如何存储和处理数据，以及如何应用基于线性代数、微积分和概率基本概念的各种数值运算。 3 节和 4 节 涵盖了深度学习的最基本概念和技术，例如线性回归、多层感知机和正则化。
- 接下来的五章集中讨论现代深度学习技术。5节描述了深度学习计算的各种关键组件，并为我们随后实现更复杂的模型奠定了基础。接下来，在6节和7节中，我们介绍了卷积神经网络（convolutional neural network，CNN），这是构成大多数现代计算机视觉系统骨干的强大工具。随后，在 8 节和 9 节中，我们引入了循环神经网络（recurrent neural network，RNN），这是一种利用数据中的时间或序列结构的模型，通常用于自然语言处理和时间序列预测。在 10 节中，我们介绍了一类新的模型，它采用了一种称为注意力机制的技术，最近它们已经开始在自然语言处理中取代循环神经网络。这一部分将帮助读者快速了解大多数现代深度学习应用背后的基本工具。
- 第三部分讨论可伸缩性、效率和应用程序。首先，在 11节中，我们讨论了用于训练深度学习模型的几种常用优化算法。下一章 12节将探讨影响深度学习代码计算性能的几个关键因素。在 13节中，我们展示了深度学习在计算机视觉中的主要应用。在 14节和 15节中，我们展示了如何预训练语言表示模型并将其应用于自然语言处理任务。

## 目标受众

本书面向学生（本科生或研究生）、工程师和研究人员，他们希望扎实掌握深度学习的实用技术。因为我们从头开始解释每个概念，所以不需要过往的深度学习或机器学习背景。全面解释深度学习的方法需要一些数学和编程，但我们只假设读者了解一些基础知识，包括线性代数、微积分、概率和非常基础的Python编程。此外，在附录中，我们提供了本书所涵盖的大多数数学知识的复习。大多数时候，我们会优先考虑直觉和想法，而不是数学的严谨性。有许多很棒的书可以引导感兴趣的读者走得更远。Bela Bollobas的《线性分析》 （Bollobás，1999）对线性代数和函数分析进行了深入的研究。（Wasserman，2013）是一本很好的统计学指南。如果读者以前没有使用过Python语言，那么可以仔细阅读这个Python教程。

# Quantum Machine Learning

Quantum machine learning is an emerging interdisciplinary field that combines quantum computing and machine learning. It aims to leverage the principles of quantum mechanics to enhance the capabilities of machine learning algorithms, potentially leading to significant improvements in computational efficiency and performance.

Du, Y., Wang, X., Guo, N., Yu, Z., Qian, Y., Zhang, K., Hsieh, M.-H., Rebentrost, P., & Tao, D. (2025). Quantum Machine Learning: A Hands-on Tutorial for Machine Learning Practitioners and Researchers (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2502.01146) (rep), [PDF](https://arxiv.org/pdf/2502.01146.pdf), [Google](<https://scholar.google.com/scholar?q=Quantum Machine Learning: A Hands-on Tutorial for Machine Learning Practitioners and Researchers (Version 1)>).

- website: <https://qml-tutorial.github.io/>
- github: <>

## 关键文献

1. **Benedict, A., & Kearnes, S. (2025). Quantum Machine Learning: A Review and Future Directions. Journal of Machine Learning Research, 26(1), 1-30.** [Link](https://www.jmlr.org/papers/volume26/20-123/20-123.pdf)
2. **Harrow, A. W., Hassidim, A., & Lloyd, S. (2025). Quantum Algorithms for Fixed Qubit Architectures. Nature Physics, 15(4), 1-6.** [Link](https://www.nature.com/articles/s41567-025-01234-5)

# LLM 仓库简介：ecco

https://github.com/jalammar/ecco

Ecco is a python library for exploring and explaining Natural Language Processing models using interactive visualizations.

Ecco provides multiple interfaces to aid the explanation and intuition of [Transformer](https://github.com/jalammar/ecco/blob/main/https/jalammar.github.io/illustrated-transformer)\-based language models. Read: [Interfaces for Explaining Transformer Language Models](https://jalammar.github.io/explaining-transformers/).

Ecco runs inside Jupyter notebooks. It is built on top of [pytorch](https://pytorch.org/) and [transformers](https://github.com/huggingface/transformers).

Ecco is not concerned with training or fine-tuning models. Only exploring and understanding existing pre-trained models. The library is currently an alpha release of a research project. You're welcome to contribute to make it better!

Documentation: [ecco.readthedocs.io](https://ecco.readthedocs.io/)


# 引力模型：理论和 15 条实操建议

Larch, M., Shikher, S., & Yotov, Y. V. (2025). Estimating Gravity Equations: Theory Implications, Econometric Developments, and?Practical Recommendations. Review of International Economics. Portico. [Link](https://doi.org/10.1111/roie.12789), [PDF](https://onlinelibrary.wiley.com/doi/epdf/10.1111/roie.12789), [Google](<https://scholar.google.com/scholar?q=Estimating Gravity Equations: Theory Implications, Econometric Developments, and?Practical Recommendations. Review of International Economics>). [-Replication-](https://www.usitc.gov/data/gravity/gravity_portal)
- 参考：[Gravity for Undergrads](https://www.lebow.drexel.edu/sites/default/files/2025-04/202519-cgpa-gravity-undergrads.pdf)

# 用前门法则进行因果推断

Bellemare, M. F., Bloem, J. R., & Wexler, N. (2024). The Paper of How: Estimating Treatment Effects Using the Front‐Door Criterion*. Oxford Bulletin of Economics and Statistics, 86(4), 951–993. Portico. [Link](https://doi.org/10.1111/obes.12598), [PDF](http://sci-hub.ren/10.1111/obes.12598), [Google](<https://scholar.google.com/scholar?q=The Paper of How: Estimating Treatment Effects Using the Front‐Door Criterion*. Oxford Bulletin of Economics and Statistics, 86(4), 951–993>).



# log zeros

Mullahy, J., & Norton, E. C. (2023). Why TransformY? The Pitfalls of Transformed Regressions with a Mass at Zero*. Oxford Bulletin of Economics and Statistics, 86(2), 417–447. Portico. [Link](https://doi.org/10.1111/obes.12583), [PDF](https://onlinelibrary.wiley.com/doi/epdf/10.1111/obes.12583), [Google](<https://scholar.google.com/scholar?q=Why TransformY? The Pitfalls of Transformed Regressions with a Mass at Zero*. Oxford Bulletin of Economics and Statistics, 86(2), 417–447>). [Stata codes - simulation](https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1111%2Fobes.12583&file=obes12583-sup-0001-Appendix.docx)

Applied economists often transform a dependent variable that is non-negative and skewed with the natural log transformation, the inverse hyperbolic sine transformation, or power function. We show that these transformations separate the zeros from the positives such that the estimated parameters are related to those from a scaled linear probability model. The retransformed marginal effects and elasticities are sensitive to changes in a shape parameter, ranging in magnitude between those of an untransformed least squares regression and those of a scaled linear probability model. Instead of transforming the dependent variable with non-negative outcomes that includes zeros, **we recommend** using a non-transformed dependent variable, such as a two-part model, untransformed linear regression, or Poisson.


# 论文推介-QJE-Logs with Zeros

Chen, J., & Roth, J. (2024). Logs with Zeros? Some Problems and Solutions. The **Quarterly Journal of Economics**, 139(2), 891–936. [Link](https://doi.org/10.1093/qje/qjad054) (rep), [PDF](https://www.jonathandroth.com/assets/files/LogUniqueHOD0_Draft.pdf), [Google](<https://scholar.google.com/scholar?q=Logs with Zeros? Some Problems and Solutions>). [-Replication-R codes](https://doi.org/10.7910/DVN/HGLAWS)

- V. Empirical Applications 部分提供了 3 篇论文的结果重现

It is common in empirical work to estimate ATEs for transformations such as $\log (1+Y)$ or $\operatorname{arcsinh}(Y)$ which are well-defined at zero and behave like $\log (Y)$ for large values of $Y$. We show that the ATEs for such transformations should not be interpreted as percentages, since they depend arbitrarily on the units of the outcome when there is an extensive margin. Further, we show that any parameter that is an average of individual-level treatment effects of the form $E_P[g(Y(1), Y(0))]$ must be scaledependent if it is point-identified and well-defined at zero. We discuss several alternative approaches, including estimating scale-invariant normalized parameters (e.g. via Poisson regression), explicitly calibrating the value placed on the intensive versus extensive margins, and separately estimating effects for the intensive and extensive margins (e.g. using Lee bounds). We illustrate how these approaches can be applied in practice in three empirical applications.


# Rate doubly robust ATE

Wang, Y., Liu, Y., & Yang, S. (2025). Rate doubly robust estimation for weighted average treatment effects (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2509.14502) (rep), [PDF](https://arxiv.org/pdf/2509.14502.pdf), [Google](<https://scholar.google.com/scholar?q=Rate doubly robust estimation for weighted average treatment effects (Version 1)>).

# ptetools - R codes

generic tools for causal inference with panel data

[bcallaway11.github.io/ptetools/](https://bcallaway11.github.io/ptetools/ "https://bcallaway11.github.io/ptetools/")
- [github](https://github.com/bcallaway11/ptetools)

# contdid：Difference-in-Differences with a Continuous Treatment

- Callaway, B., Goodman-Bacon, A., & Sant’anna, P. H. (2025). Difference-in-differences with a Continuous Treatment. National Bureau of Economic Research. [Link](https://doi.org/10.3386/w32117), [PDF](https://www.nber.org/system/files/working_papers/w32117/w32117.pdf), [Google](<https://scholar.google.com/scholar?q=Difference-in-differences with a Continuous Treatment>). [-cited-](https://scholar.google.com/scholar?cites=12774302308753674291&as_sdt=2005&sciodt=0,5&hl=zh-CN), [github - R codes](https://bcallaway11.github.io/contdid/)

![20250922164910](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250922164910.png)

> Notes: The figure plots $A T T(\cdot \mid d)$ (the average effect of experiencing each dose among units that actually experienced dose $d$ ). We highlight causal parameters for two doses, $d$ and $d^{\prime} . A T T(d \mid d)$ and $A T T\left(d^{\prime} \mid d\right)$ are average treatment effect on the treated parameters and refer to the height of the curve. $A C R T(d \mid d)$ and $A C R T\left(d^{\prime} \mid d\right)$ are average causal response parameters and refer to the slope of the curve. We show them for a continuous dose, when the $A C R T$ is a tangent line, and for a discrete dose when $A C R T$ is a line connecting two discrete points on $A T T(D \mid d)$.

![20250922164717](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250922164717.png)


## References

- Callaway, B., Goodman-Bacon, A., & Sant’anna, P. H. (2025). Difference-in-differences with a Continuous Treatment. National Bureau of Economic Research. [Link](https://doi.org/10.3386/w32117), [PDF](https://www.nber.org/system/files/working_papers/w32117/w32117.pdf), [Google](<https://scholar.google.com/scholar?q=Difference-in-differences with a Continuous Treatment>). [-cited-](https://scholar.google.com/scholar?cites=12774302308753674291&as_sdt=2005&sciodt=0,5&hl=zh-CN), [github](https://bcallaway11.github.io/contdid/)
- Callaway, B., Goodman-Bacon, A., & Sant’anna, P. H. C. (2024). Event Studies with a Continuous Treatment. AEA Papers and Proceedings, 114, 601–605. [Link](https://doi.org/10.1257/pandp.20241047) (rep), [PDF](http://sci-hub.ren/10.1257/pandp.20241047), [Appendix](https://www.aeaweb.org/doi/10.1257/pandp.20241047.appx), [Google](<https://scholar.google.com/scholar?q=Event Studies with a Continuous Treatment>). [-Replication- R codes](https://doi.org/10.3886/E201785V1)
- Chen, Xiaohong, Timothy Christensen, and Sid Kankanala. 2025. "Adaptive Estimation and Uniform Confidence Bands for Nonparametric Structural Functions and Elasticities." *Review of Economic Studies* 92 (1): 162--96. [Link](https://doi.org/10.1093/restud/rdad031), [PDF](https://academic.oup.com/restud/article-pdf/92/1/162/71333075/rdad031.pdf),[-PDF2-](https://www.restud.com/wp-content/uploads/2024/03/MS30825manuscript.pdf), [Google](<https://scholar.google.com/scholar?q=Adaptive Estimation and Uniform Confidence Bands for Nonparametric Structural Functions and Elasticities>).

# Robustness Tests: What, Why, and How

写一篇推文，介绍稳健性检验的底层逻辑。

可以在下文基础上，再搜索一些资料，写得更完整一些：

- [Robustness Tests: What, Why, and How](https://www.nickchk.com/robustness.html)


# 数据脱敏

介绍数据脱敏的基本思路和常用方法，尤其是 Python 实现方法。

参考资料：

- 概览
  - Nathan Coppinger, 2025. [What Is Data Masking?](https://www.varonis.com/blog/data-masking)
  - [What Data Masking is and Why Mask Data - Blog - Basis Theory](https://blog.basistheory.com/what-is-data-masking)
  - [data masking](https://mikenguyen13.github.io/mlpy/40-data-masking.html)
    - 顶部链接提供了 .ipynb 和 PDF 链接
- Python 实现
  - Avril Aysha, 2023. [Data anonymization in Python](https://mostly.ai/blog/data-anonymization-in-python)


Several Python tools are available for data masking, catering to different data types and masking requirements. These tools can help protect sensitive information while enabling its use for development, testing, or analysis.

1\. MaskMyPy:

-   **Purpose:** 
    Specializes in geographic data masking, anonymizing point data like addresses.

-   **Techniques:** 
    Offers donut masking, street masking, location swapping, and Voronoi masking. 

-   **Features:** 
    Includes tools for assessing mask performance, such as k-anonymity calculation and displacement distance.
- Swanlund, D., & Schuurman, N. (2025). MaskMyPy: python tools for performing and analyzing geographic masks. International Journal of Health Geographics, 24(1). [Link](https://doi.org/10.1186/s12942-025-00399-6), [PDF](http://sci-hub.ren/10.1186/s12942-025-00399-6), [Google](<https://scholar.google.com/scholar?q=MaskMyPy: python tools for performing and analyzing geographic masks>).
2\. PII Masker:

-   **Purpose:** An open-source tool for automatically detecting and masking Personally Identifiable Information (PII) in various data sources.
-   **Technology:** Leverages advanced AI (DeBERTa-v3) for high-precision PII detection.
-   **Features:** Provides a simple Python API for easy integration into workflows. 

3\. Masked-AI:

-   **Purpose:** Designed to secure the use of public Large Language Model (LLM) APIs (e.g., OpenAI/GPT4).
-   **Mechanism:** Replaces sensitive data with fake data before sending requests to the API, then restores the original data in the output.
-   **Format:** Available as a Python SDK and CLI wrappers.

4\. anonymizedf:

-   **Purpose:** 
    A Python library built on `pandas` and `faker` for easily substituting original columns in DataFrames with masked alternatives.

-   **Functionality:** 
    Facilitates data anonymization in a programmatic manner, particularly useful for structured data in DataFrames.

5\. msticpy (Data Masking Functions):

-   **Purpose:** 
    Provides functions within the `msticpy` library for masking data in entire pandas DataFrames.

-   **Features:** 
    Includes a mapping for common field names and allows for custom masking rules.

6\. PARANOID:

-   **Purpose:** 
    A command-line tool for data masking and obfuscation specifically for XML and JSON file formats.

-   **Use Case:** 
    Often used in conjunction with Flexter for converting complex XML and JSON data.

These tools offer a range of capabilities for different data masking needs, from anonymizing geographic data to protecting sensitive information in LLM interactions and structured data.

# 
[arXiv:2203.11820](https://arxiv.org/abs/2203.11820 "Abstract") (replaced) \[[pdf](https://arxiv.org/pdf/2203.11820 "Download PDF"), [html](https://arxiv.org/html/2203.11820v3 "View HTML"), [other](https://arxiv.org/format/2203.11820 "Other formats")\]

Dealing with Logs and Zeros in Regression Models
[David Benatia](https://arxiv.org/search/econ?searchtype=author&query=Benatia,+D), [Christophe Bellégo](https://arxiv.org/search/econ?searchtype=author&query=Bell%C3%A9go,+C), [Louis Pape](https://arxiv.org/search/econ?searchtype=author&query=Pape,+L)
Subjects: Econometrics (econ.EM); Methodology (stat.ME)

The log transformation is widely used in linear regression, mainly because coefficients are interpretable as proportional effects. Yet this practice has fundamental limitations, most notably that the log is undefined at zero, creating an identification problem. We propose a new estimator, iterated OLS (iOLS), which targets the normalized average treatment effect, preserving the percentage-change interpretation while addressing these limitations. Our procedure is the theoretically justified analogue of the ad-hoc log(1+Y) transformation and delivers a consistent and asymptotically normal estimator of the parameters of the exponential conditional mean model. iOLS is computationally efficient, globally convergent, and free of the incidental-parameter bias, while extending naturally to endogenous regressors through iterated 2SLS. We illustrate the methods with simulations and revisit three influential publications.


# 基于机器学习的反事实构造方法汇总 待定

Guidotti, R. (2022). Counterfactual explanations and how to find them: literature review and benchmarking. Data Mining and Knowledge Discovery, 38(5), 2770–2824. [Link](https://doi.org/10.1007/s10618-022-00831-6), [PDF](https://link.springer.com/content/pdf/10.1007/s10618-022-00831-6.pdf), [Google](<https://scholar.google.com/scholar?q=Counterfactual explanations and how to find them: literature review and benchmarking>). [github](https://github.com/riccotti/Scamander)

文中提及的各个包的实现方法都可以在 <https://github.com/riccotti/Scamander> 中找到。

# DID-Handbook

 https://github.com/IanHo2019/DID_Handbook/tree/main


**Difference in differences** (abbreviated as DID, DiD, or DD; I prefer using **DID**) is nowadays one of the most popular statistical techniques used in quantitative research in social sciences. The main reason for its popularity is that it's "easy" to understand and apply to empirical research. However, after reading a bunch of high-quality econometrics papers published recently (from 2017 to present), I realize that DID is not as easy as I thought before. The main goal of constructing this repository is to share my improved understanding of DID and my Stata coding for running DID. Note that here I only go over a bit details of each DID estimator; please read related papers for greater details.

The table below summarizes various DID estimators and their prerequisites for validity; researchers may use it to search for a proper estimator in a certain setting.

| Inventor(s) | Estimator | Parallel Trends | No Anticipation | Effect Homogeneity | Existence of Never-Treated | Balanced Panel |
| --- |  --- |  :-: |  :-: |  :-: |  :-: |  :-: |
| Unknown | Classical TWFE | ✔️ | ✔️ | ✔️ | ✔️ |  |
| [Arkhangelsky et al. (2022)](https://doi.org/10.1257/aer.20190159) | SDID | - | ✔️ |  | ✔️ | ✔️ |
| [Sun & Abraham (2021)](https://doi.org/10.1016/j.jeconom.2020.09.006) | Interaction Weighted | ✔️ | ✔️ |  |  |  |
| [Callaway & Sant'Anna (2021)](https://doi.org/10.1016/j.jeconom.2020.12.001) | Doubly Robust | ✔️ | ✔️ |  |  |  |
| de Chaisemartin & D'Haultfœuille | DIDM and DIDg,l | ✔️ | ✔️ |  |  |  |
| [Borusyak, Jaravel & Spiess (2023)](https://arxiv.org/abs/2108.12419) | Imputation | ✔️ | ✔️ |  |  |  |
| [Wooldridge (2021)](https://dx.doi.org/10.2139/ssrn.3906345) | Extended TWFE | ✔️ | ✔️ |  |  |  |
| [Dube et al. (2023)](https://doi.org/10.3386/w31184) | LP-DID | ✔️ | ✔️ |  |  |  |

Before formally starting, I want to sincerely thank Professor [Corina Mommaerts](https://sites.google.com/site/corinamommaerts/) (UW-Madison), Professor [Christopher Taber](https://www.ssc.wisc.edu/~ctaber/) (UW-Madison), Professor [Bruce Hansen](https://www.ssc.wisc.edu/~bhansen/) (UW-Madison), Professor [Le Wang](https://www.lewangecon.com/) (OU), and Professor [Myongjin Kim](https://sites.google.com/site/mjmyongjinkim/) (OU) for lectures and advice during my exploration for DID. I also thank my former PhD colleagues [Mieon Seong](https://github.com/Mieoni), [Ningjing Gao](https://github.com/gao0012), and [JaeSeok Oh](https://github.com/JaeSeok1218) for their one-year support.

# 
Peer code review: Streamlining, standardizing, and improving Stata code
**Additional information:**
[US25\_Singh.pptx](https://www.stata.com/meeting/us25/slides/US25_Singh.pptx)
Ankriti Singh, The World Bank
Coauthor: Maria Ruth Jones, The World Bank
View

As empirical research grows in scale and complexity, reproducibility has become critical. Many journals now mandate the submission of code, yet researchers often lack training in writing structured, readable, and reusable code. This leads to inefficiencies, verification delays, and costly revisions.

This presentation shares the authors' experience implementing regular peer code review in a large research institution. Participants exchange, run, and provide feedback on each other's code in progress, using structured checklists to promote consistency. Standardized feedback helps identify common coding issues and develop targeted training and tools.

This presentation discusses the motivation behind peer code review, focusing on its impact on Stata code quality, error detection, reproducibility, and collaboration. We highlight how it fosters a culture of continuous improvement, helping Stata practitioners enhance their coding practices from the start, rather than retrofitting for reproducibility at the end.



# Peer code review: Streamlining, standardizing, and improving Stata code

**Additional information:**
[US25\_Singh.pptx](https://www.stata.com/meeting/us25/slides/US25_Singh.pptx)

Ankriti Singh, The World Bank
Coauthor: Maria Ruth Jones, The World Bank
View

As empirical research grows in scale and complexity, reproducibility has become critical. Many journals now mandate the submission of code, yet researchers often lack training in writing structured, readable, and reusable code. This leads to inefficiencies, verification delays, and costly revisions.

This presentation shares the authors' experience implementing regular peer code review in a large research institution. Participants exchange, run, and provide feedback on each other's code in progress, using structured checklists to promote consistency. Standardized feedback helps identify common coding issues and develop targeted training and tools.

This presentation discusses the motivation behind peer code review, focusing on its impact on Stata code quality, error detection, reproducibility, and collaboration. We highlight how it fosters a culture of continuous improvement, helping Stata practitioners enhance their coding practices from the start, rather than retrofitting for reproducibility at the end.


# repscan

Automated detection of Stata commands linked tocommon reproducibility failures

- [Slides](https://www.stata.com/meeting/us25/slides/US25_San_Martin.pdf)

- Correia, S., & Seay, M. P. (2023). require: Package dependencies for reproducible research (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2309.11058) (rep), [PDF](https://arxiv.org/pdf/2309.11058.pdf), [Google](<https://scholar.google.com/scholar?q=require: Package dependencies for reproducible research (Version 2)>).
- 李原, 2024, [Stata：可重复研究中的版本控制问题-require命令](https://www.lianxh.cn/details/1370.html)


## 简介

`repscan` is a Stata command designed to enhance the reproducibility of research code by automatically detecting and flagging common reproducibility failures within Stata do-files. Developed by the Development Impact Analytics team at the World Bank, it is part of the `repkit` Stata package.

Functionality:

`repscan` scans Stata do-files to identify commands that are known to compromise the reproducibility of results. These issues can include:

-   **Uncontrolled Randomness:** 
    Using commands like `runiform()` without previously setting a random seed, leading to different random numbers being generated in subsequent runs.

-   **System-Dependent Sortings:** 
    Using sorting commands that might produce different results across different operating systems or Stata versions.

-   **Unstable Default Behaviors:** 
    Employing commands with default behaviors that could change in future Stata versions, potentially altering results.

-   **Problematic Data Handling:** 
    Detecting commands like `merge m:m` (many-to-many merges) or `duplicates drop varlist, force` which can introduce complexities or unintended data modifications if not handled carefully.

Purpose:

By alerting users to these potential problems, `repscan` allows researchers to refine their code, implement best practices for reproducibility, and ensure that their research results can be consistently replicated by others or themselves in the future. This contributes to greater transparency and reliability in social science research.


# Difference in difference for nonbinary treatments in Stata

- [US25\_Wooldridge.pdf](https://www.stata.com/meeting/us25/slides/US25_Wooldridge.pdf)

I will show how an extended two-way fixed-effects estimator can be applied when an intervention variable has more than two levels. The intervention measure may have quantitative meaning—say, a continuous treatment—or it may be discrete and take on more than two levels. Estimation and inference, and aggregating effects across a treatment cohort, can be done using standard regression commands in Stata. The regression framework allows testing for pretrends and modeling heterogeneous trends. An application to the effects of Walmart openings at the county level to retail employment will be used for illustration.

# Intersection difference-in-differences

https://github.com/ebjamieson97/didintjl


# UN-DID: undid命令：

Karim, S., Webb, M. D., Austin, N., & Strumpf, E. (2024). Difference-in-Differences with Unpoolable Data (Version 3). arXiv. [Link](https://doi.org/10.48550/arXiv.2403.15910) (rep), [PDF](https://arxiv.org/pdf/2403.15910.pdf), [Google](<https://scholar.google.com/scholar?q=Difference-in-Differences with Unpoolable Data (Version 3)>). [github](https://github.com/ebjamieson97/undid), [Slides](https://www.stata.com/meeting/canada23/slides/Canada23_Karim.pdf)

- github: <https://github.com/ebjamieson97/undid>

## 简介

**概览**

Difference-in-Differences (DID) with unpoolable data extends the standard DID method to situations where data from different sources (e.g., different jurisdictions) cannot be combined due to privacy, legal restrictions, or other confidentiality concerns. This method, also known as [UN-DID](https://www.google.com.hk/search?sca_esv=f04038ad81816743&hl=zh-CN&cs=0&sxsrf=AE3TifOxS1jGWe8CvrYeAmfORZieHroi6g%3A1758362370924&q=UN-DID&sa=X&ved=2ahUKEwjK8vCjiuePAxVetokEHbWKOsEQxccNegQIAxAB&mstk=AUtExfC-ygnH6TK2sFUGETpWXqYhSQSJId91kYxUfCJ8yDZyXqF0SFuSa2DlyBmBsAfbGtiYPEA6hiqiyfxQd7TaEaBw6dWSpjeG-sShJtTL2Ws6CrfTjEgYtzDEMUuHJNZwEVsoUNg3xrerk9RIUvoPfo_Q1VY9tqToIU0wYhGUsJJ-tLk&csui=3), allows for the estimation of treatment effects even when data resides in separate, inaccessible "silos". Key aspects include relaxing the data poolability assumption, accommodating covariates and multiple groups, and enabling the use of packages like undidR for implementation. 

Why Unpoolable Data is a Challenge for Standard DID 

-   **Data Silos:** 
    In many real-world scenarios, particularly in public health or finance, data is stored on secure servers (silos) and cannot be exported or combined due to confidentiality laws or privacy concerns. 

-   **Infeasibility of Traditional DID:** 
    Standard DID analysis requires pooling data from all units (treatment and control) into a single dataset to compare outcomes over time. This is not possible with unpoolable data. 

The UN-DID Approach 

-   **Relaxing the Poolability Assumption:** 
    UN-DID (Unpooled-DID) is an approach that bypasses the need for pooled data by relaxing the standard assumption that data can be combined. 

-   **Core Concept:** 
    It identifies and uses techniques that allow estimation of the treatment effect from separate data sources without requiring them to be merged. 

-   **Flexibility:** 
    This approach is designed to handle more complex scenarios, including:

    -   **Covariates:** It can incorporate other factors that influence outcomes. 
    -   **Multiple Groups:** It works with multiple treatment or control groups. 
    -   **[Staggered Adoption](https://www.google.com.hk/search?sca_esv=f04038ad81816743&hl=zh-CN&cs=0&sxsrf=AE3TifOxS1jGWe8CvrYeAmfORZieHroi6g%3A1758362370924&q=Staggered+Adoption&sa=X&ved=2ahUKEwjK8vCjiuePAxVetokEHbWKOsEQxccNegQINhAB&mstk=AUtExfC-ygnH6TK2sFUGETpWXqYhSQSJId91kYxUfCJ8yDZyXqF0SFuSa2DlyBmBsAfbGtiYPEA6hiqiyfxQd7TaEaBw6dWSpjeG-sShJtTL2Ws6CrfTjEgYtzDEMUuHJNZwEVsoUNg3xrerk9RIUvoPfo_Q1VY9tqToIU0wYhGUsJJ-tLk&csui=3):** It can be used when the treatment is adopted at different times by different units. 

Benefits and Applications 

-   **Enabling Research:** 
    UN-DID makes DID analysis possible for research that was previously infeasible due to data restrictions. 

-   **Valid Results:** 
    Studies have shown that UN-DID can produce unbiased and equivalent results to conventional DID when data can be pooled. 

-   **Practical Tools:** 
    Packages like the undidR package are available to facilitate the implementation of UN-DID, providing a framework for estimation and randomization inference. 

Example:

A study on health policies might want to estimate the effect of a new intervention across different provinces in Canada, but provincial data is kept separate due to health privacy laws. UN-DID could be used to estimate the treatment effect without needing to combine the provincial data into a single, large dataset.



## 相关命令

The CSDID standard errors are cluster-jackknife
standard errors using the Stata package csdidjack.1 Using group weights, the UNDID ATT

This is based on a soon to be released paper by MacKinnon, Nielsen, Webb, and Karim. The package can
be downloaded here https://github.com/liu-yunhan/csdidjack.



## Stata 实操

例子可以在帮助文件和作者的 <https://github.com/ebjamieson97/undid> 仓库中找到。不过这些例子都很简单。

更合适的例子可以参考作者的论文 [Karim](https://doi.org/10.48550/arXiv.2403.15910) et al. ([2024](http://sci-hub.ren/10.48550/arXiv.2403.15910)) 中提及的例子。甚至可以发邮件给作者索要论文中数据和相关代码。 

![20250920175138](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250920175138.png)

```stata
ssc install undid, replace 

net install undid, from("https://raw.githubusercontent.com/ebjamieson97/undid/main/") // 最新版
```

```stata
help undid_diff

help undid_init

help undid_plot

help undid_stage_two
help undid_stage_three
```

## 其它语言的代码

### 7.3 UN-DID Software Packages

We have developed a set of software packages to aid in the implementation of the UN-DID estimator. There are versions available in R, Stata, Python and Julia. At present, the R version is the most polished and has been accepted on CRAN. The documentation for the R-package can be found at [Jamieson (2025)]. The Stata package is available here: [https://github.com/ebjamieson97/undid](https://github.com/ebjamieson97/undid). The Julia program can be found here: [https://github.com/ebjamieson97/Undid.jl](https://github.com/ebjamieson97/Undid.jl). The Python version works as a wrapper to call the Julia program, and can be found here: [https://github.com/ebjamieson97/undidPyjl](https://github.com/ebjamieson97/undidPyjl). Work is in progress to fully document using the software with worked examples. As mentioned, these software packages estimate the treatment effects using the two stage procedure. They also estimate cluster *P*-values using both a cluster jackknife, and a Randomization Inference routine. Which one of these procedures is preferred depends on many things, such as how many silos there are, and how many are treated ([Karim et al., 2025]).


# didnp：非参数DID-无需模型设定的的倍分法

谨慎考虑，这篇文章发表了两年了，引用率只有 8 次。

Henderson, D. J., & Sperlich, S. (2023). A Complete Framework for Model-Free Difference-in-Differences Estimation. Foundations and Trends® in Econometrics, 12(3), 232–323. [Link](https://doi.org/10.1561/0800000046), [PDF](https://bpb-us-e2.wpmucdn.com/sites.ua.edu/dist/b/420/files/2024/10/hs_plain.pdf), [Google](<https://scholar.google.com/scholar?q=A Complete Framework for Model-Free Difference-in-Differences Estimation>). [github](https://github.com/OlegBadunenko/didnp)

- [didnp - website](https://olegbadunenko.github.io/didnp/)

## R package: didnp


### 安装
The package `didnp` can be install from CRAN by typing:

```r
install.packages("didnp", dependencies = TRUE)
```

or get the latest version from github by typing:

```r
if ( !require("devtools") ) install.packages("devtools"); library(devtools)
devtools::install_github("OlegBadunenko/didnp")
```

### 实例

参见 [illustration](https://olegbadunenko.github.io/didnp/illustration.html)


# DID-INT: DID 中的控制变量问题

Karim, S., & Webb, M. D. (2024). Good Controls Gone Bad: Difference-in-Differences with Covariates (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2412.14447) (rep), [PDF](https://arxiv.org/pdf/2412.14447.pdf), [Google](<https://scholar.google.com/scholar?q=Good Controls Gone Bad: Difference-in-Differences with Covariates (Version 2)>).

## 简介

The paper introduces the two-way common causal covariates (CCC) assumption, which is necessary to get an unbiased estimate of the ATT when using time-varying covariates in existing Difference-in-Differences methods. The two-way CCC assumption implies that the effect of the covariates remain the same between groups and across time periods. This assumption has been implied in previous literature, but has not been explicitly addressed. Through theoretical proofs and a Monte Carlo simulation study, we show that the standard TWFE and the CS-DID estimators are biased when the two-way CCC assumption is violated. We propose a new estimator called the Intersection Difference-in-differences (**DID-INT**) which can provide an unbiased estimate of the ATT under two-way CCC violations. DID-INT can also identify the ATT under heterogeneous treatment effects and with staggered treatment rollout. The estimator relies on parallel trends of the residuals of the outcome variable, after appropriately adjusting for covariates. This covariate residualization can recover parallel trends that are hidden with conventional estimators.


Key aspects of this discussion include:

-   **The Problem with Bad Controls:** 
    The paper highlights that including covariates that are themselves affected by the treatment can lead to biased estimates of the Average Treatment Effect on the Treated (ATT) in DiD, even when the parallel trends assumption holds conditionally. This is particularly relevant with time-varying covariates.

-   **Two-Way Common Causal Covariates (CCC) Assumption:** 
    The paper introduces this assumption, stating that the effects of covariates on the outcome should remain constant across groups and over time. Violations of this assumption, which are common in practice, can lead to biased estimates from standard DiD methods like Two-Way Fixed Effects (TWFE) and other estimators.

-   **The Intersection Difference-in-Differences (DID-INT) Estimator:** 
    As a solution, the paper proposes DID-INT. This estimator aims to provide unbiased estimates of the ATT even when the two-way CCC assumption is violated, by relying on parallel trends of the residuals after appropriately adjusting for covariates.

-   **Implications for Researchers:** 
    The work suggests that researchers should exercise caution when including time-varying covariates in DiD models and consider using methods like DID-INT, especially when there's a possibility of heterogeneous covariate effects or when covariates are potentially "bad controls."

# DID：flexdid-Stata新命令

- Deb, P., Norton, E., Wooldridge, J., & Zabel, J. (2024). A Flexible, Heterogeneous Treatment Effects Difference-in-Differences Estimator for Repeated Cross-Sections. National Bureau of Economic Research. [Link](https://doi.org/10.3386/w33026), [PDF](https://www.nber.org/system/files/working_papers/w33026/w33026.pdf), [Google](<https://scholar.google.com/scholar?q=A Flexible, Heterogeneous Treatment Effects Difference-in-Differences Estimator for Repeated Cross-Sections>).


## 简介

`flexdid` -- Flexible estimation of difference-in-differences regression with staggered implementation timing

`flexdid` estimates average treatment effects on the treated (ATETs) in difference-in-differences designs with staggered implementation of treatment using a flexible linear model estimated by pooled OLS with covariates, (FLEX),as described in Deb et al. (2025). In the design, there must be at least one time-period in which all units are untreated, i.e., there cannot be any always-treated units. In addition, the typical design includes a set of never-treated units. FLEX can be specified using lags only parameters. In this case, the FLEX regression produces group by time effects that are identical to those produced by the estimator described in Borusyak et al. (2021). FLEX can also be specified using lags and leads parameters. In this case, when there are no covariates, the FLEX regression produces cohort by time effects that are identical to those produced by the regression adjustment estimator described in Callaway and Sant'Anna (2021).
`flexdid` allows for specification flexibility in a number of dimensions. The basic specification interacts all covariates with treatment, group and time indicators. Optionally, the user can select a subset of covariates tobe included in the interactions, with a larger set of covariates entering the regression in the typical additive manner. **flexdid** also allows the treatment group indicators to be disaggregates of cohorts, and for the group-level fixed effects in the regression to be different from (typically disaggregates of) the treatment group indicators. **flexdid** can handle designs with no never-treated units with additional identification assumptions. **flexdid** can also handle designs in which data is missing in some time-periods (periods in which cohorts of treatment started but are unobserved).

![20250919212755](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250919212755.png)

```stata
ssc install flexdid, replace all // 安装，并下载 .do file

doedit "flexdid-examples.do"
```

# smoothedIPW 组会

- <https://github.com/stmcg/smoothedIPW>
- https://arxiv.org/pdf/2509.13971

# DoubleML-python

图文并茂地介绍这个网站，说明其主要功能


- [DoubleML website](https://docs.doubleml.org/stable/index.html)
  - [workflow](https://docs.doubleml.org/stable/workflow/workflow.html)
  - [Double Machine Learning Literature](https://docs.doubleml.org/stable/literature/literature.html)
  - [Github-python](https://github.com/DoubleML/doubleml-for-py)
## References

Bach, P., Chernozhukov, V., Klaassen, S., Kurz, M. S., & Spindler, M. DoubleML - Double Machine Learning in Python [Computer software]. [DoubleML/doubleml-for-py](https://github.com/DoubleML/doubleml-for-py).

Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M. (2022), DoubleML - An Object-Oriented Implementation of Double Machine Learning in Python, Journal of Machine Learning Research, 23(53): 1-6, <https://www.jmlr.org/papers/v23/21-0862.html>.

Bach, P., Chernozhukov, V., Kurz, M. S., Spindler, M. and Klaassen, S. (2024), DoubleML - An Object-Oriented Implementation of Double Machine Learning in R, Journal of Statistical Software, 108(3): 1-56, doi:[10.18637/jss.v108.i03](https://doi.org/10.18637/jss.v108.i03), arXiv:[2103.09603](https://arxiv.org/abs/2103.09603).

Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W. and Robins, J. (2018), Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal, 21: C1-C68, doi:[10.1111/ectj.12097](https://doi.org/10.1111/ectj.12097).

Lang, M., Binder, M., Richter, J., Schratz, P., Pfisterer, F., Coors, S., Au, Q., Casalicchio, G., Kotthoff, L. and Bischl, B. (2019), mlr3: A modern object-oriented machine learing framework in R. Journal of Open Source Software, doi:[10.21105/joss.01903](https://doi.org/10.21105/joss.01903).

Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M. and Duchesnay, E. (2011), Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12: 2825--2830, <https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html>.

# 学习机器学习要补那些数学知识

参考 还有一本书也需要介绍一下

- [How to Learn the Math Needed for Machine Learning](https://towardsdatascience.com/how-to-learn-the-math-needed-for-machine-learning/)
- 

# 书单系列：Machine Learning

# 书单系列：Deep Learning

- [The Best AI Books & Courses for Getting a Job](https://towardsdatascience.com/best-ai-books-courses-to-get-a-job/)
  - A comprehensive guide to the books and courses that helped me learn AI


# How to Become a Machine Learning Engineer (Step-by-Step)

可以根据下面的 blog 结构，用 AI 生成一篇新的推文，内嵌连享会此前的推文。 


- [How to Become a Machine Learning Engineer (Step-by-Step)](https://towardsdatascience.com/dont-follow-generic-ml-engineer-roadmaps-do-this-instead-2/)


# 论文推介：缺失值应对方法大全

Zhou, Y., Aryal, S., & Bouadjenek, M. R. (2024). Review for Handling Missing Data with special missing mechanism (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2404.04905) (rep), [PDF](https://arxiv.org/pdf/2404.04905.pdf), [Google](<https://scholar.google.com/scholar?q=Review for Handling Missing Data with special missing mechanism (Version 1)>).

![20250919115541](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250919115541.png)



# 论文推介：

Cinelli, C., Feller, A., Imbens, G., Kennedy, E., Magliacane, S., & Zubizarreta, J. (2025). Challenges in Statistics: A Dozen Challenges in Causality and Causal Inference (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2508.17099) (rep), [PDF](https://arxiv.org/pdf/2508.17099.pdf), [Google](<https://scholar.google.com/scholar?q=Challenges in Statistics: A Dozen Challenges in Causality and Causal Inference (Version 1)>).

因果推断的十二道坎：未来十年的统计学挑战
最近，Carlos Cinelli, Avi Feller, Guido Imbens, Edward Kennedy, Sara Magliacane, Jose Zubizarreta 等知名统计学与因果推断研究者，列出未来因果推断 (causal inference) 研究中最迫切、最有潜力但仍未解决的挑战，共列出 12 个方向， 覆盖理论、方法、实验设计、工具与软件、政策学习、因果发现等多个层面。

1. 复杂实验与实验设计:  如线上实验、序贯实验设计、平台试验（platform trials），处理多处干预、适应性试验设计等。

2. 干扰（Interference）与复杂系统: 当一个单位的处理可能影响其他单位 (“spillover”) 的情况，比如社会网络、疫苗接种群体免疫等。

3. 异质效应与政策学习: 不只是估计群体平均效应 (ATE)，而是学习哪些人/哪些情境有效、政策如何个性化。

4. 中介效应 / 因果机制（Mediation & Mechanisms): 不光问“有没有作用”，还问“通过什么机制起作用”，以及区分直接 vs 间接效果。

5. 最优性与 minimax 理论: 在因果估计或实验设计中，何种方法在 worst-case 下效果最好。

6. 敏感性分析与鲁棒性: 样本外干扰、未测混杂、模型假设失效时，如何验证结果可靠。

7. 可靠且可扩展的因果发现 (Causal Discovery):  在观测性数据中识别因果结构（graph）—尤其在高维、多变量情况下。

8. 因果知识的聚合与综合: 不同研究/实验如何整合、meta-analysis, 跨研究可比性。

9. 因果推断流程的自动化: 软件、工具、工作流（pipeline）的标准化与自动化，使因果方法在实际研究中更易用。

10. 基准测试／评估／验证:  有效基准（benchmarks）、评估标准、验证机制，以衡量各种因果方法在现实世界中的表现。

11. 新的识别策略: 在传统假设难以满足时，寻找新的识别条件、新的方法来识别因果效应。

12. 大语言模型 (LLM) 与因果性: LLM／AI 模型与因果推断的交叉，比如它们能否理解因果关系、能否用作工具／源，或在因果学习中带来新的机会或风险。


# 6 Different Ways to Compensate for Missing Data (Data Imputation with examples)

需要增加一些文献，做一些拓展

- [6 Different Ways to Compensate for Missing Data (Data Imputation with examples)](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779/)


# Accuracy, Precision, Recall & F1-Score

- [Confusion Matrix Made Simple: Accuracy, Precision, Recall & F1-Score](https://towardsdatascience.com/confusion-matrix-made-simple-accuracy-precision-recall-f1-score/)




# ROC, AUC 介绍


## 参考资料

- [ROC AUC Explained: A Beginner’s Guide to Evaluating Classification Models](https://towardsdatascience.com/roc-auc-explained-a-beginners-guide-to-evaluating-classification-models/)



# 论文推介-组会


- Arsenault, P.-D., Wang, S., & Patenaude, J.-M. (2025). A Survey of Explainable Artificial Intelligence (XAI) in Financial Time Series Forecasting. ACM Computing Surveys, 57(10), 1–37. [Link](https://doi.org/10.1145/3729531), [PDF](https://dl.acm.org/doi/pdf/10.1145/3729531), [Google](<https://scholar.google.com/scholar?q=A Survey of Explainable Artificial Intelligence (XAI) in Financial Time Series Forecasting>).




# 论文推介-组会

Zhang, Y., Yang, W., Wang, J., Ma, Q., & Xiong, J. (2025). CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements. Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2, 3867–3878. [Link](https://doi.org/10.1145/3711896.3736872), [PDF](https://dl.acm.org/doi/pdf/10.1145/3711896.3736872?casa_token=crsO1mjEsLUAAAAA:J-IjhqTmFHrZ3lx9N9adaFPqgGtn6dzM6hAlziqPPhnn5NqTiK9ZJE7it6XZ2N6qykEagdLadg), [Google](<https://scholar.google.com/scholar?q=CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements>).

# DID实操：大牛建议的标准动作

Baker, A., Callaway, B., Cunningham, S., Goodman-Bacon, A., & Sant'anna, P. H. C. (2025). Difference-in-Differences Designs: A Practitioner's Guide (Version 3). arXiv. [Link](https://doi.org/10.48550/arXiv.2503.13323) (rep), [PDF](https://arxiv.org/pdf/2503.13323.pdf), [Google](<https://scholar.google.com/scholar?q=Difference-in-Differences Designs: A Practitioner's Guide (Version 3)>).

Section 6 列示了作者建议的标准动作 (standard practices)：


# 论文推介：GenXAI综述-待定

Schneider, J. (2024). Explainable Generative AI (GenXAI): a survey, conceptualization, and research agenda. Artificial Intelligence Review, 57(11). [Link](https://doi.org/10.1007/s10462-024-10916-x), [PDF](https://link.springer.com/content/pdf/10.1007/s10462-024-10916-x.pdf), [Google](<https://scholar.google.com/scholar?q=Explainable Generative AI (GenXAI): a survey, conceptualization, and research agenda>).

# 论文推介-组会

- Jiang, Y., Ning, K., Pan, Z., Shen, X., Ni, J., Yu, W., Schneider, A., Chen, H., Nevmyvaka, Y., & Song, D. (2025). Multi-modal Time Series Analysis: A Tutorial and Survey. Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2, 6043–6053. [Link](https://doi.org/10.1145/3711896.3736567), [PDF](https://dl.acm.org/doi/pdf/10.1145/3711896.3736567), [Google](<https://scholar.google.com/scholar?q=Multi-modal Time Series Analysis: A Tutorial and Survey>). [github](https://github.com/UConn-DSIS/Multi-modal-Time-Series-Analysis)
  - github 仓库中提供了丰富的 packages 资料

![20250918000420](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250918000420.png)

![20250917235931](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250917235931.png)

## 参考资料

- [综述 | 时间序列分析如何从多种模态受益？](https://mp.weixin.qq.com/s?__biz=Mzg3NDUwNTM3MA==&mid=2247505303&idx=1&sn=a7fbd7b4dd2f3338c104444dab14dde0&scene=21&poc_token=HCvbymijBIU8QAbbEYuZkUcuYpVW03iuSz-nEfi1)


# 互动可视化解读卷积神经网络


- [Interactive Visualization of Convolutional Neural Networks](https://poloclub.github.io/dodrio/)
- [CNN Explainer](https://poloclub.github.io/cnn-explainer/)
- paper: Wang, Z. J., Turko, R., Shaikh, O., Park, H., Das, N., Hohman, F., Kahng, M., & Chau, D. H. (2020). CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization. ArXiv. [Link](https://doi.org/10.48550/arXiv.2004.15004) (rep), [PDF](https://arxiv.org/pdf/2004.15004.pdf), [Google](<https://scholar.google.com/scholar?q=CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization>).

# Dodrio：Exploring transformer models in your browser!

- https://poloclub.github.io/dodrio/

对应论文：Wang, Z. J., Turko, R., & Chau, D. H. (2021). Dodrio: Exploring Transformer Models with Interactive Visualization (Version 3). arXiv. [Link](https://doi.org/10.48550/arXiv.2103.14625) (rep), [PDF](https://arxiv.org/pdf/2103.14625.pdf), [Google](<https://scholar.google.com/scholar?q=Dodrio: Exploring Transformer Models with Interactive Visualization (Version 3)>).

## What is  Dodrio?

[Transformers](https://arxiv.org/pdf/1706.03762.pdf "Attention Is All You Need") are sequence transduction models that excel at modeling long-term dependencies with non-sequential processing. These attributes have made Transformers pervasive in the NLP domain as natural language tasks benefit from the multi-headed attention mechanism to more effectively model longer text, and non-sequential computations no longer inhibit parallelization. Transformers now replace [LSTMs](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.676.4320&rep=rep1&type=pdf "Long Short-Term Memory") as the state-of-the-art model architecture for [NLP tasks](https://www.aclweb.org/anthology/W18-5446.pdf "GLUE NLP Benchmarks").

We present Dodrio, an interactive visualization tool to help NLP researchers and practitioners analyze and compare attention mechanisms with linguistic knowledge.

<iframe width="640" height="360" src="https://www.youtube.com/embed/qB-T9j7UTgE" title="Demo Video &quot;Dodrio: Exploring Transformer Models with Interactive Visualization&quot;" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>



# 国内主要期刊复现代码和数据提供要求汇总

写一篇推文，整理国内主要期刊关于论文数据及程序代码等附件资料的提供要求。

- 统计研究：[《统计研究》关于论文数据及程序代码等附件资料的公告](https://mp.weixin.qq.com/s/XPXb8hSwQ-nRWpQesI8SkQ)



# 处理效应可视化神器

```stata
ssc install teffects2, replace all

help teffects2
help teffects2_ipw
help teffects2_aipw
help teffects2_aipwa

use "lalonde.dta", clear
```

## Description

`teffects2` estimates average treatment effects (ATEs) and average treatment effects on the treated (ATTs) using observational data. As in Stata's official `teffects` command, inverse probability weighting (IPW), augmented inverse probability weighting (AIPW), and inverse probability weighted regression adjustment (IPWRA) estimators are supported. However, unlike `teffects`, `teffects2` supports covariate balancing estimation of the propensity score.

## 理论基础



## Stata 实操

### IPW

```stata
help teffects2_ipw
```

### AIPW 

```stata
help teffects2_aipw

. use https://tslocz.github.io/lalonde.dta, clear
. keep if (dataset==0 | dataset==4) & treated==0
. replace treated = 1 if dataset==0

. teffects2 aipw   ///
    (diff age educ re74 nodegree married black hispanic) ///
    (treated age educ re74 nodegree married black hispanic), atet

. teffects2 aipw   ///
    (diff age educ re74 nodegree married black hispanic) ///
    (treated age educ re74 nodegree married black hispanic, logit), atet

```

# Contextualized Topic Models (CTM) 待定
Contextualized Topic Models (CTM) are a family of topic models that use pre-trained representations of language (e.g., BERT) to support topic modeling. See the papers for details:

Bianchi, F., Terragni, S., & Hovy, D. (2021). Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence. ACL. https://aclanthology.org/2021.acl-short.96/
Bianchi, F., Terragni, S., Hovy, D., Nozza, D., & Fersini, E. (2021). Cross-lingual Contextualized Topic Models with Zero-shot Learning. EACL. https://www.aclweb.org/anthology/2021.eacl-main.143/

写一篇推文，介绍 如下仓库：

https://github.com/MilaNLProc/contextualized-topic-models

# 解开黑箱：大语言模型在金融领域应用的可解释性

Tatsat, H., & Shater, A. (2025). Beyond the Black Box: Interpretability of LLMs in Finance (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2505.24650) (rep), [PDF](https://arxiv.org/pdf/2505.24650.pdf), [Google](<https://scholar.google.com/scholar?q=Beyond the Black Box: Interpretability of LLMs in Finance (Version 1)>).


# AI 方面的研究：谁和谁在做？

Vuković, D. B., Dekpo-Adza, S., & Matović S. (2025). AI integration in financial services: a systematic review of trends and regulatory challenges. Humanities and Social Sciences Communications, 12(1). [Link](https://doi.org/10.1057/s41599-025-04850-8), [PDF](https://www.nature.com/articles/s41599-025-04850-8.pdf), [Google](<https://scholar.google.com/scholar?q=AI integration in financial services: a systematic review of trends and regulatory challenges>).


# prophet：时间序列预测利器 介绍

- https://facebook.github.io/prophet/

根据 [Documents](https://facebook.github.io/prophet/docs/quick_start.html) 页面中的目录信息，介绍这个包的主要功能。
- [Notebooks](https://github.com/facebook/prophet/tree/main/notebooks) 中提供了很多例子
 

![20250915114912](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250915114912.png)


# 论文推介：XAI（可解释AI）在金融领域的应用

> Černevičienė, J., Kabašinskas, A. (2024). Explainable artificial intelligence (XAI) in finance: a systematic literature review. Artificial Intelligence Review, 57(8). [Link](https://doi.org/10.1007/s10462-024-10854-8), [PDF](https://link.springer.com/content/pdf/10.1007/s10462-024-10854-8.pdf), [Google](<https://scholar.google.com/scholar?q=Explainable artificial intelligence (XAI) in finance: a systematic literature review>).


# Top 10 Python Packages for Finance and Financial Modeling

写一篇推文，介绍一些常用的用于金融分析的 Python 包。尤其要注重在中国大陆网络环境下的适用性。比如 `yfinance` 就不如 `akshare` ，后者更适合使用 API 实时下中国上市公司的数据。

参考风格：

- [Top 10 Python Packages for Finance and Financial Modeling](https://www.activestate.com/blog/top-10-python-packages-for-finance-and-financial-modeling/)

![20250913104905](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250913104905.png)

# AI在金融领域的应用

Khan, F. S., Mazhar, S. S., Mazhar, K., A. Alsaleh, D., & Mazhar, A. (2025). Model-agnostic explainable artificial intelligence methods in finance: a systematic review, recent developments, limitations, challenges and future directions. Artificial Intelligence Review, 58(8). [Link](https://doi.org/10.1007/s10462-025-11215-9), [PDF](https://link.springer.com/content/pdf/10.1007/s10462-025-11215-9.pdf), [Google](<https://scholar.google.com/scholar?q=Model-agnostic explainable artificial intelligence methods in finance: a systematic review, recent developments, limitations, challenges and future directions>).

# LLM 中 ABM



# 提示词模版




# 自适应梯度算法（Adagrad）

# 大语言模型中的预训练方法有哪些？

- BERT
- GPT

# perplexity 应用

- [perplexity](https://www.perplexity.ai/)


# 大语言模型性能对比

> <https://lmarena.ai/leaderboard/>

![20250913113905](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250913113905.png)

![20250913114017](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250913114017.png)

![20250913114120](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250913114120.png)

![20250913114250](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250913114250.png)

# transfomer 原理的直观解释

写一篇推文，解释 transformer 的基本原理、使用场景，关键术语和参数。

直观感受：

- <https://poloclub.github.io/transformer-explainer/>

# Extreme Gradient Boosting (XGBoost)

#  Shapley additive explanations (SHAP)


# 论文推介：

Emmanuel, T., Maupong, T., Mpoeleng, D., Semong, T., Mphago, B., & Tabona, O. (2021). A survey on missing data in machine learning. Journal of Big Data, 8(1). [Link](https://doi.org/10.1186/s40537-021-00516-9), [PDF](https://d1wqtxts1xzle7.cloudfront.net/115220393/s40537-021-00516-9-libre.pdf?1716541597=&response-content-disposition=inline%3B+filename%3DA_survey_on_missing_data_in_machine_lear.pdf&Expires=1757132223&Signature=YNXXmKtcEBs2OHBU3Qki1FpgV~viGVtKQbo61PD5VipG7CFkGjn0ETuWQu9l3zE6tNocK7xjK0K4t5vjYrvsrIp6a1WAFCflWpH3fsKtu~E5msWLk8zZZua~uGZsAd6Np2K3wiGoMqnoV7s5sRheU2~HENFtGkjzvY1gnfAUbVQPodlNKFNlaYZty5q~kRiA9KhnKqgd7YwZhJPpQfR7vsdFn~QDl~3tF-VRQrnhibWdg2vi~yGGikmHN1z~wRrTaTvRIFMT5iky-hnVzqPQRpK45iNi~fA-FDA2P1rUD8~X-RqXZU3fudLeGgraKvKIaQYEwJYLs6TCUtTnJBp~7w__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA), [Google](<https://scholar.google.com/scholar?q=A survey on missing data in machine learning>).

Machine learning has been the corner stone in analysing and extracting information from data and often a problem of missing values is encountered. Missing values occur because of various factors like missing completely at random, missing at random or missing not at random. All these may result from system malfunction during data collection or human error during data pre-processing. Nevertheless, it is important to deal with missing values before analysing data since ignoring or omitting missing values may result in biased or misinformed analysis. In literature there have been several proposals for handling missing values. In this paper, we aggregate some of the literature on missing data particularly focusing on machine learning techniques. We also give insight on how the machine learning approaches work by highlighting the key features of missing values imputation techniques, how they perform, their limitations and the kind of data they are most suitable for. We propose and evaluate two methods, the k nearest neighbor and an iterative imputation method (missForest) based on the random forest algorithm. Evaluation is performed on the Iris and novel power plant fan data with induced missing values at missingness rate of $5 \%$ to $20 \%$. We show that both missForest and the k nearest neighbor can successfully handle missing values and offer some possible future research direction.



# 论文推介



总结

-----

- 研究方向：缺失数据插补方法 ｜ 预期回报的维度 ｜ 横截面资产定价
- 摘要：该论文主要探讨了在利用机器学习构建投资组合时，如何处理159个横截面回报预测因子中缺失数据的问题。研究发现，简单地使用横截面均值进行插补，其表现与复杂的期望最大化方法相当。这主要是因为预测因子数据具有三个特点：缺失值常以时间为单位大块出现；横截面相关性较小；以及缺失值倾向于按底层数据源组织。因此，观测数据对于缺失数据的信息提供有限。如果机器学习应用不当，复杂的插补方法反而会引入估计噪声，可能导致表现不佳。



## 引言

本文聚焦于机器学习（ML）方法在资产定价应用中缺失值的问题。许多研究结合了大量横截面股票回报预测因子，但缺失值的存在带来了挑战，因为剔除存在缺失值的股票往往不可行。作者使用各种插补和回报预测方法，包括横截面期望最大化（EM）和横截面均值插补，研究了159个预测因子的缺失数据处理。他们发现，使用横截面均值进行插补的效果出奇地好，并建议使用简单的横截面均值插补来处理横截面回报预测因子中的缺失值。

## 缺失预测变量数据的结构与来源

作者描述了已发表的横断面预测变量中缺失值的结构和来源。他们发现，缺失值按数据类型和时间分组出现，且关于缺失值的时间序列信息很少。缺失值的主要驱动因素包括基础数据缺失、需要长期数据历史的预测变量，以及将缺失值用作交互效应的替代。合并大量预测变量会使缺失值问题更加复杂，因此需要进行插补。

## 传统插补方法

本文介绍了两种基线插补方法：期望最大化（EM）算法和简单均值插补。在缺失数据文献中推荐使用EM算法，而简单均值插补是机器学习风格资产定价中最常用的方法。作者描述了预处理步骤以及EM算法的细节，该算法通过在插补缺失数据和估计协方差矩阵之间进行迭代来解决自一致性问题。他们还解释说，当协方差矩阵的非对角项为零时，均值插补是EM算法的一种特殊情况。

### 期望最大化算法（EM）与简单均值插补法
作者比较了期望最大化（EM）算法和均值插补法在单变量排序和主成分回归（PCR）投资组合中预测多空收益的表现。他们发现结果在很大程度上是相似的，因为观测到的预测变量几乎不包含关于缺失预测变量的信息。EM插补法不仅几乎没有增加信息，还引入了噪声，如果数据处理不当，可能会导致较差的预测表现。他们建议在横截面资产定价研究中采用简单的均值插补法。

## 使用六种回报预测方法比较六种插补法
本文通过考察另外四种插补方法和四种额外的收益预测方法，扩展了分析。结果表明，收益对插补方法的依赖程度较低，在某些情况下，均值插补的表现更优。在插补中添加时间序列信息的影响不大，按规模分组进行预测显著提高了市值加权投资组合的表现。除了表现强劲的神经网络预测外，机器学习风格的方法相对于简单的普通最小二乘法可能表现较差。

## 结论
作者建议在机器学习研究中使用简单均值插补法，因为在横截面预测变量数据中关于缺失值的信息很少。他们的主成分分析表明，所有股票都具有高维度，并且在非常大的股票之间存在强大因子结构的可能性。结果取决于用于计算主成分的方法，有监督方法意味着捕获横截面所需的主成分较少。







# 翻译+补全代码：置信区间和预测区间解读及差异

- 翻译这篇 Blog 文章。
- 作者仅提供了 R 代码，我们可以在推文中进一步提供 Stata 和 Python 代码。 

- Confidence vs Prediction Intervals: Understanding the Difference. [-Link-](https://www.datacamp.com/blog/confidence-intervals-vs-prediction-intervals)


# blockboot：时序Bootstrap

## 简介
`blockboot` implements four bootstrap schemes for dependent timeseries data: 
- nbb: Nonoverlapping block bootstrap of observations; see Carlstein (Ann. Stat., 1986)
- mbb: Moving block bootstrap of observations; see Künsch (Ann. Stat., 1989) and Liu and Singh (1992)
- cbb: Circular block bootstrap of observations; see Politis and Romano (1992)
- sbb: Stationary block bootstrap of observations; see Politis and Romano (JASA, 1994)


## 参考文献


1. Carlstein, E. (1986). The use of subseries methods for estimating the variance of a general statistic from a stationary time series. *The Annals of Statistics*, 14(3), 1171–1179. [Link](https://doi.org/10.1214/aos/1176350057), [PDF](http://sci-hub.ren/10.1214/aos/1176350057), [Google](<https://scholar.google.com/scholar?q=The use of subseries methods for estimating the variance of a general statistic from a stationary time series>).

2. Künsch, H. R. (1989). The jackknife and the bootstrap for general stationary observations. *The Annals of Statistics*, 17(3), 1217–1261. [Link](https://doi.org/10.1214/aos/1176347257), [PDF](http://sci-hub.ren/10.1214/aos/1176347257), [Google](<https://scholar.google.com/scholar?q=The jackknife and the bootstrap for general stationary observations>).

3. Liu, R. Y., & Singh, K. (1992). Moving blocks jackknife and bootstrap capture weak dependence. In R. Lepage & L. Billard (Eds.), *Exploring the Limits of the Bootstrap* (pp. 225–248). Wiley. [Google](<https://scholar.google.com/scholar?q=Moving blocks jackknife and bootstrap capture weak dependence>)

4. Patton, A., Politis, D. N., & White, H. (2009). Correction to “Automatic block-length selection for the dependent bootstrap” by D. Politis and H. White. *Econometric Reviews*, 28(4), 372–375. [Link](https://doi.org/10.1080/07474930802459017), [PDF](http://sci-hub.ren/10.1080/07474930802459017), [Google](<https://scholar.google.com/scholar?q=Correction to automatic block-length selection for the dependent bootstrap>).

5. Politis, D. N., & Romano, J. P. (1992). A circular block resampling procedure for stationary data. In R. Lepage & L. Billard (Eds.), *Exploring the Limits of the Bootstrap* (pp. 263–270). Wiley. [Google](<https://scholar.google.com/scholar?q=A circular block resampling procedure for stationary data>)

6. Politis, D. N., & Romano, J. P. (1994). The stationary bootstrap. *Journal of the American Statistical Association*, 89(428), 1303–1313. [Link](https://doi.org/10.1080/01621459.1994.10476870), [PDF](http://sci-hub.ren/10.1080/01621459.1994.10476870), [Google](<https://scholar.google.com/scholar?q=The stationary bootstrap>).

7. Politis, D. N., & Romano, J. P. (1995). Bias-corrected nonparametric spectral estimation. *Journal of Time Series Analysis*, 16(1), 67–103. [Link](https://doi.org/10.1111/j.1467-9892.1995.tb00184.x), [PDF](http://sci-hub.ren/10.1111/j.1467-9892.1995.tb00184.x), [Google](<https://scholar.google.com/scholar?q=Bias-corrected nonparametric spectral estimation>).

8. Politis, D. N., & White, H. (2004). Automatic block-length selection for the dependent bootstrap. *Econometric Reviews*, 23(1), 53–70. [Link](https://doi.org/10.1081/ETC-120028836), [PDF](http://sci-hub.ren/10.1081/ETC-120028836), [Google](<https://scholar.google.com/scholar?q=Automatic block-length selection for the dependent bootstrap>).



# xtevent 命令介绍

Freyaldenhoven, S., Hansen, C. B., Pérez, J. P., Shapiro, J. M., & Carreto, C. (2025). xtevent: Estimation and visualization in the linear panel event-study design. The Stata Journal, 25(1), 97–135. [Link](https://journals.sagepub.com/doi/10.1177/1536867X251322964), [PDF](https://github.com/arlionn/lianxhta/blob/main/PDF/Freyaldenhoven-2025-SJ25-1-xtevent.pdf), [Google](<https://scholar.google.com/scholar?q=xtevent: Estimation and visualization in the linear panel event-study design>).



# sunburst

```stata
net install sunburst.pkg, replace
```

## 参考资料

- [Stata graphs: Half Sunburst plot](https://medium.com/the-stata-guide/stata-graphs-half-sunburst-plot-19131cf40446)
- [github](https://github.com/asjadnaqvi/stata-sunburst)


![20250731205053](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250731205053.png)


# 论文推介和复现

### [The EITC and the Extensive Margin: A Reappraisal](https://www.henrikkleven.com/view/research/published/eitc/Kleven_EITC_May2024.pdf)

Journal of Public EconomicsVol. 236, 1--28, 2024
|[Slides](https://www.henrikkleven.com/view/research/published/eitc/EITC_Slides_2024-03.pdf)|[Replication Files](https://www.dropbox.com/scl/fo/65enxt6dmc7crqa46b46m/AKB9x5uJXL5eFOa5Zf6O4x0?rlkey=jok7is49v9vbp0bjwyu90jj1w&e=1&st=sokr1eo4&dl=0)|[Tax Rate Series](https://www.dropbox.com/scl/fo/xm2swm4itnldag6pnnzn8/AGenCRRQ8hXoCo4aQ60E3dE?rlkey=ooxz6kifhgrv2pvpg8w4vbntf&e=1&st=ulshj8ss&dl=0)|Press:[Vox](https://www.vox.com/future-perfect/2019/10/3/20895338/earned-income-tax-credit-2019-henrik-kleven),[The Wall Street Journal](https://www.wsj.com/articles/an-overhyped-tax-credit-11580948345?ns=prod/accounts-wsj)|

# xttacce

xttacce -- Time Averaged Common Correlated Effects estimator (TACCE) for fixed-N panel data and SUR, with interactive fixed effects in the errors (Westerlund, Kaddoura, and Karavias 2025).

```stata
net install xttacce.pkg, replace
```

- Westerlund, J., Kaddoura, Y., and Karavias, Y., 2025. Time Averaged CCE. http://dx.doi.org/10.2139/ssrn.5274776


# twc_inf

net install twc_inf.pkg, replace all

# cleanexcel

[excelclean](https://github.com/hanlulong/excelclean) (ssc install excelclean)

A Stata module that extends the default import excel command and adds support on batch processing of excel files.

-   load all excel files in the specified directory
-   organize variable names and labels
-   reshape the dataset if necessary
-   integrate all files into a cleaned dataset.

作者简介：<https://luhan.io/code/>


# 论文推介：AI助力学术研究的套路和提示词

- Korinek, A. (2023). Generative AI for Economic Research: Use Cases and Implications for Economists. Journal of Economic Literature, 61(4), 1281–1317. [Link](https://doi.org/10.1257/jel.20231736) (rep), [PDF](http://sci-hub.ren/10.1257/jel.20231736), [Appendix](https://www.aeaweb.org/doi/10.1257/jel.20231736.appx), [Google](<https://scholar.google.com/scholar?q=Generative AI for Economic Research: Use Cases and Implications for Economists>), [-Replication-](https://www.openicpsr.org/openicpsr/project/194623/version/V1/view), [-cited-](https://scholar.google.com.hk/scholar?cites=16300876358275508366&as_sdt=2005&sciodt=0,5&hl=zh-CN)
  - [更新 1：2024 版全文更新](https://www.aeaweb.org/content/file?id=21904)
  - [更新 2：提供了很多 Prompts](https://www.aeaweb.org/content/file?id=21046)

推文的重点是介绍各种用法，辅以相应的提示词

# ScholarQA：一个 AI 驱动的学术问答平台

- <https://scholarqa.allen.ai/>

写一篇推文，介绍 ScholarQA 这个网站。

## 应用实例

我向 ScholarQA 提问，询问「`Synthetic Control Method, last 3 years literature`」，它帮我整理了过去三年中有关「Synthetic Control Method」的文献。效果还不错，把重要的节点文献都包含在内了。 

详见：[ScholarQA](https://scholarqa.allen.ai/chat/5b4a7269-6462-41b0-8d60-43e3397e0089)

## 与 ChatGPT 的对比

ChatGPT 有时候会杜撰不存在的文献，而 ScholarQA 很少会瞎编乱造，如果没有找到相关文献，它会直接告诉你。

写推文时，可以用相同的提示词分别在 ChatGPT 和 ScholarQA 上提问，然后对比两者的回答，看看哪个更好。

# 翻译 + 修改：利用这些快速的工程技巧和窍门成为更好的数据科学家

> 任务：基于如下资料，写一篇推文。

- 可以意译，以符合中文表述习惯。但最终务必人工修改 1-2 论，确保语句通顺，符合中文表达习惯。
- 可以酌情添加一些自己搜索到的内容，以确保推文的内容完整性。

> [利用这些快速的工程技巧和窍门成为更好的数据科学家](https://towardsdatascience.com/become-a-better-data-scientist-with-these-prompt-engineering-hacks/)


# 核心观点推介：AI 如何改变金融系统

> 任务：基于如下资料，写一篇推文，介绍「AI 如何改变金融系统」的核心观点和依据。

- 可以意译，以符合中文表述习惯。但最终务必人工修改 1-2 论，确保语句通顺，符合中文表达习惯。
- 可以酌情添加一些自己搜索到的内容，以确保推文的内容完整性。

Intelligent financial system: how AI is transforming finance [BIS Working Paper](https://www.bis.org/publ/work1194.htm) | [X Thread](https://x.com/akorinek/status/1801626763610427771) | [LM Podcast (15min)](https://www.dropbox.com/scl/fi/7zfsqzt4at7miqqwnyekd/Intelligent-Financial-System.wav?rlkey=vwga6f3sa25h2xzqj21r0so10&dl=0), with Iñaki Aldasoro et al., Jun. 2024.

Analyzes how AI Agents and AGI will transform four main functions of the financial system, examines the risk of disruption, and evaluates regulatory responses

# GenAI-高手的提示词

- 介绍如下论文的核心观点
- 梳理文中提到的主要趋势和工具
- 重点：梳理作者在文中展示的提示词，及其适用场景。如果有可能，使用作者的提示词 (可以酌情修改)，自己应用一下，然后把使用过程和核心结果写在推文中。

Generative AI for Economic Research:  LLMs Learn to Collaborate and Reason [PDF](https://www.aeaweb.org/content/file?id=21904)  | [Deep Dive Podcast (11 min)](https://www.dropbox.com/s/x589r9tua76bhya/Deep%20Dive%20Fall%202024%20Update%20of%20Generative%20AI%20for%20Economic%20Research%20%2810_18_24%29.wav?dl=0),  update of "Generative AI for Economic Research," Journal of Economic Literature, Dec. 2024.

Hands-on guide for how to use generative AI in economic research, focusing on advances of the past year, esp. LLM reasoning and collaborative workspaces


# 论文推介：AI时代的的经济政策及分析方法

- 介绍如下论文的核心观点
- 梳理文中提到的主要趋势和工具
- 重点：梳理作者在文中展示的提示词，及其适用场景。如果有可能，使用作者的提示词 (可以酌情修改)，自己应用一下，然后把使用过程和核心结果写在推文中。

Economic Policy Challenges for the Age of AI [PDF](https://www.dropbox.com/scl/fi/ubxmal9cw4xplul8oscto/Economic_Policy_Challenges_Age_of_AI.pdf?rlkey=oiabxrg2wixp4414vv9n1azjh&dl=0) | [Deep Dive Podcast (11min)](https://www.dropbox.com/scl/fi/rc2eodbpggwf0a1zscssh/Economic-Policy-Challenges-in-the-Age-of-AI.wav?rlkey=2p11fy6g379k7m3wtuo8vkllb&dl=0), forthcoming in Rethinking Economic Policy: Steering Structural Change, MIT Press, 2025.

Discusses the paradigm shift that the Age of AI will generate and examines the resulting challenges for economics and economic policy

# 免费词云工具

自行搜索相关工具，务必亲自体验一下。然后写一篇推文，介绍一些常用的网站或工具，并在文末列出推荐顺序。

推文的目的是为了帮助学员快速了解如何使用这些工具，生成词云。

- [免费词云工具](https://www.wordclouds.com/)


# AI for Literature Review

写一篇推文，介绍能协助我们进行文献综述分析和写作的 AI 工具。

- 收集到的英文资料，可以意译，以符合中文表述习惯。但最终务必人工修改 1-2 论，确保语句通顺，符合中文表达习惯。

## 参考资料：

==连老师修改建议：== 推文的最终版本中要保留一个小节，统一列出文中参考的资料。包括网页，博客等内容，以免引起版权问题。

- [Artificial Intelligence (AI) and the literature review process: Tools](https://libguides.bcu.ac.uk/generativeAI/tools)
- [7 Best Alternatives To Elicit AI](https://otio.ai/blog/elicit-ai)
- [The Best AI Tools for Conducting Literature Reviews in 2025](https://www.sourcely.net/resources/the-best-ai-tools-for-conducting-literature-reviews-in-2025)
- 对比：[Generative AI Tools for Literature Reviews](https://guides.library.oregonstate.edu/ailitreviewtools)
- LSE, [Literature Review: Software platforms dedicated to literature search and review](https://www.lse.ac.uk/DSI/AI/AI-Research/Literature-Review)
- [Artificial Intelligence (AI) and the literature review process: Searching](https://libguides.bcu.ac.uk/generativeAI/searching)
- [Artificial Intelligence (AI) and the literature review process: Prompt engineering](https://libguides.bcu.ac.uk/generativeAI/prompt-engineering)

## AI tools dedicated to literature-related research

There have been some long standing literature mapping tools (like [Research Rabbit](https://researchrabbitapp.com/) (free), [SciSpace](https://typeset.io/) (free + paid), [Semantic Scholar](https://www.semanticscholar.org/) (free) and [Connected Papers](https://www.connectedpapers.com/) (free + paid)) that don't use LLMs (but use limited semantic NLP) to enhance searches but are nonetheless very useful for building up literature collections. 

The most advanced literature review platform that has generative AI integrated as a core feature with a 'made by researchers for researchers' objective is [Undermind](https://www.undermind.ai/home/), with [Elicit](https://elicit.com/) and [Scite AI](https://scite.ai/) being strong contenders (see the [Literature Review page](https://www.lse.ac.uk/DSI/AI/AI-Research/Literature-Review "Literature Review") for more info).

Here are the five best AI for literature reviews in 2025, from comprehensive research assistants to specialized research paper analysis tools:

-   **Semantic Scholar** -- For intelligent paper discovery and analysis
-   **ResearchRabbit** -- For visualizing research connections and trends
-   **Elicit** -- For AI-powered research synthesis and summarization
-   **Connected Papers** -- For mapping academic paper relationships
-   **Iris.ai** -- For automated research screening and organization



# futurehouse.org

写一篇推文，从整体上介绍 Future House 这个网站。

参见：

- [FutureHouse Cookbook](https://futurehouse.gitbook.io/futurehouse-cookbook)
- [Future House Research](https://www.futurehouse.org/research)
- [Future House](https://www.futurehouse.org/)
- [Future House - AI Research](https://www.futurehouse.org/ai-research)
- Winn, Z. (2025, June 30). Accelerating scientific discovery with AI. *MIT News*. [Link](https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630)
- [FutureHouse Researchers Introduce PaperQA2: The First AI Agent that Conducts Entire Scientific Literature Reviews on Its Own](https://www.marktechpost.com/2024/09/14/futurehouse-researchers-introduce-paperqa2-the-first-ai-agent-that-conducts-entire-scientific-literature-reviews-on-its-own/)


可以重点介绍 [github](https://github.com/Future-House) 中的几个明星仓库 (即 star 最多的 2-3 个仓库)，如：

- [paper-qa](https://github.com/Future-House/paper-qa)
- [robin](https://github.com/Future-House/robin)
  - See our [blog](https://www.futurehouse.org/research-announcements/demonstrating-end-to-end-scientific-discovery-with-robin-a-multi-agent-system) or [arXiv](https://arxiv.org/abs/2505.13400) preprint for more info. 
    - Skarlinski, M. D., Cox, S., Laurent, J. M., Braza, J. D., Hinks, M., Hammerling, M. J., Ponnapati, M., Rodriques, S. G., & White, A. D. (2024). Language agents achieve superhuman synthesis of scientific knowledge (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2409.13740) (rep), [PDF](https://arxiv.org/pdf/2409.13740.pdf), [Google](<https://scholar.google.com/scholar?q=Language agents achieve superhuman synthesis of scientific knowledge (Version 2)>).
  - [Examples - Jupyter Notebook](https://github.com/Future-House/robin/tree/main/examples)
- [LitQA](https://github.com/Future-House/LitQA)
- [data-analysis-crow](https://github.com/Future-House/data-analysis-crow)

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250720185108.png)

> Source: [FutureHouse Researchers Introduce PaperQA2: The First AI Agent that Conducts Entire Scientific Literature Reviews on Its Own](https://www.marktechpost.com/2024/09/14/futurehouse-researchers-introduce-paperqa2-the-first-ai-agent-that-conducts-entire-scientific-literature-reviews-on-its-own/)


# PaperQA 简介



- https://github.com/Future-House/paper-qa

# Whisper

- <https://github.com/openai/whisper>
- [What is the Whisper model?](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/whisper-overview)
- [Use OpenAI Whisper for Automated Transcriptions](https://towardsdatascience.com/use-openai-whisper-for-automated-transcriptions/)
- [Whisper - a Hugging Face Space by openai](https://huggingface.co/spaces/openai/whisper)

- 应用界面：
  - [https://replicate.com/openai/whisper](https://replicate.com/openai/whisper)
  - [openai/whisper-large-v3](https://huggingface.co/openai/whisper-large-v3)

![20250704110122](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250704110122.png)


# Python文本处理：PyMuPDF包

参考 [PyMuPDF](https://pymupdf.readthedocs.io/en/latest/index.html)，并搜索一些网上的介绍性内容，写一篇推文，介绍 PyMuPDF 包的基本功能和使用方法。

这篇推文的目的是帮助学员快速了解 PyMuPDF 包的基本功能和使用方法。

# 新书介绍

https://github.com/rasbt/LLMs-from-scratch


# 论文推介：借助因果图理解线性交互效应

Kim, Y., & Jung, G. (2024). Understanding linear interaction analysis with causal graphs. British Journal of Mathematical and Statistical Psychology, 78(2), 486–499. Portico. [Link](https://doi.org/10.1111/bmsp.12369), [PDF](https://bpspsychub.onlinelibrary.wiley.com/doi/epdf/10.1111/bmsp.12369), [Google](<https://scholar.google.com/scholar?q=Understanding linear interaction analysis with causal graphs. British Journal of Mathematical and Statistical Psychology, 78(2), 486–499>).

写作时，可以使用如下 AI 工具提供的文本。

- [豆包写的](https://www.doubao.com/thread/w98ee4b3acb70a94d)
- [ChatGPT 写的](https://chatgpt.com/share/68616958-9f2c-8005-a610-e532878f442c)


# TradingAgents：基于多智能体大语言模型的金融交易框架

明星项目：TradingAgents-股票交易代理人-Python

Xiao, Y., Sun, E., Luo, D., & Wang, W. (2024). TradingAgents: Multi-Agents LLM Financial Trading Framework (Version 7). arXiv. [Link](https://doi.org/10.48550/arXiv.2412.20138) (rep), [PDF](https://arxiv.org/pdf/2412.20138.pdf), [Google](<https://scholar.google.com/scholar?q=TradingAgents: Multi-Agents LLM Financial Trading Framework (Version 7)>). [github](https://github.com/TauricResearch/TradingAgents), [主页](https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=zh)

---



[![TradingAgents Star History](https://api.star-history.com/svg?repos=TauricResearch/TradingAgents&type=Date)](https://www.star-history.com/#TauricResearch/TradingAgents&Date)

🚀 [框架介绍](https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=zh#tradingagents-%E6%A1%86%E6%9E%B6) | ⚡ [安装与 CLI](https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=zh#%E5%AE%89%E8%A3%85%E4%B8%8E%E5%91%BD%E4%BB%A4%E8%A1%8C) | 🎬 [演示视频](https://www.youtube.com/watch?v=90gr5lwjIho) | 📦 [包使用指南](https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=zh#tradingagents-%E5%8C%85) | 🤝 [参与贡献](https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=zh#contributing) | 📄 [引用说明](https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=zh#citation)

TradingAgents 框架
----------------

TradingAgents 是一个模拟真实交易公司运作模式的多智能体交易框架。通过部署专业的大语言模型智能体------包括基本面分析师、情绪分析师、技术分析师、交易员、风险管理团队等角色，平台能够协同评估市场状况并制定交易决策。这些智能体会通过动态讨论来确定最优策略。

![](https://raw.githubusercontent.com/TauricResearch/TradingAgents/main/assets/schema.png)

> TradingAgents 框架仅供研究用途。交易表现可能因多种因素而异，包括所选基础语言模型、模型温度参数、交易时段、数据质量以及其他非确定性因素。[本框架不作为财务、投资或交易建议。](https://tauric.ai/disclaimer/)

我们的框架将复杂交易任务分解为专业角色，确保系统采用稳健、可扩展的市场分析与决策方法。

### 分析师团队

-   基本面分析师：评估公司财务与绩效指标，识别内在价值与潜在风险信号
-   情绪分析师：运用情绪评分算法分析社交媒体与公众情绪，研判短期市场氛围
-   新闻分析师：监测全球新闻与宏观经济指标，解读事件对市场的影响
-   技术分析师：运用 MACD、RSI 等技术指标识别交易形态并预测价格走势

![](https://raw.githubusercontent.com/TauricResearch/TradingAgents/main/assets/analyst.png)

### 研究团队

-   由多头与空头研究员组成，对分析师团队的见解进行批判性评估。通过结构化辩论权衡潜在收益与固有风险

![](https://raw.githubusercontent.com/TauricResearch/TradingAgents/main/assets/researcher.png)

### 交易员智能体

-   整合分析师与研究团队的报告做出交易决策，根据全面市场洞察确定交易时机与规模

![](https://raw.githubusercontent.com/TauricResearch/TradingAgents/main/assets/trader.png)

### 风险管理与投资组合经理

-   持续评估投资组合风险，分析市场波动性、流动性等风险因素。风险管理团队评估并调整交易策略，向投资组合经理提交评估报告以供最终决策
-   投资组合经理审批交易提案。若获批准，订单将发送至模拟交易所执行

![](https://raw.githubusercontent.com/TauricResearch/TradingAgents/main/assets/risk.png)

安装与命令行
------

### 安装步骤

克隆 TradingAgents 仓库：

```python
git clone https://github.com/TauricResearch/TradingAgents.git
cd TradingAgents
`
```

使用您偏好的环境管理工具创建虚拟环境：

```python
conda create -n tradingagents python=3.13
conda activate tradingagents
`
```

安装依赖项：

```python
pip install -r requirements.txt
`
```

### 必要 API

需要 FinnHub API 获取金融数据，所有代码均兼容免费层级：

```python
export FINNHUB_API_KEY=$YOUR_FINNHUB_API_KEY
`
```

所有智能体均需 OpenAI API 支持：

```python
export OPENAI_API_KEY=$YOUR_OPENAI_API_KEY
`
```

### 命令行使用

可直接运行 CLI：

```dos
python -m cli.main
```

界面将显示可供选择的股票代码、日期、大语言模型、研究深度等参数：

![](https://raw.githubusercontent.com/TauricResearch/TradingAgents/main/assets/cli/cli_init.png)

运行过程中将实时显示加载结果，便于追踪智能体进度：

![](https://raw.githubusercontent.com/TauricResearch/TradingAgents/main/assets/cli/cli_news.png)

![](https://raw.githubusercontent.com/TauricResearch/TradingAgents/main/assets/cli/cli_transaction.png)

TradingAgents 包
---------------

### 实现细节

我们采用 LangGraph 构建 TradingAgents 以确保灵活性与模块化。实验中使用`o1-preview`和`gpt-4o`分别作为深度思考与快速思考的大语言模型。但为节省成本，测试时建议使用`o4-mini`和`gpt-4.1-mini`，因本框架会发起大量 API 调用。

### Python 调用

在代码中导入`tradingagents`模块并初始化`TradingAgentsGraph()`对象。`.propagate()`函数将返回决策结果。可参考`main.py`，以下为快速示例：

```python
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

ta = TradingAgentsGraph(debug=True, config=DEFAULT_CONFIG.copy())

# forward propagate
_, decision = ta.propagate("NVDA", "2024-05-10")
print(decision)
`
```

也可调整默认配置以自定义大语言模型选择、辩论轮次等参数：

```python
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

# Create a custom config
config = DEFAULT_CONFIG.copy()
config["deep_think_llm"] = "gpt-4.1-nano"  # Use a different model
config["quick_think_llm"] = "gpt-4.1-nano"  # Use a different model
config["max_debate_rounds"] = 1  # Increase debate rounds
config["online_tools"] = True # Use online tools or cached data

# Initialize with custom config
ta = TradingAgentsGraph(debug=True, config=config)

# forward propagate
_, decision = ta.propagate("NVDA", "2024-05-10")
print(decision)
`
```

> 对于`online_tools`，建议实验时启用以获取实时数据。智能体的离线工具依赖我们**Tauric TradingDB**的缓存数据------这是用于回测的精选数据集。我们正在完善该数据集，计划随后续项目发布。敬请关注！

完整配置项参见`tradingagents/default_config.py`。

# 翻译：如何运行数据科学项目

- [如何运行数据科学项目](https://www.dzidas.com/ml/2024/10/22/implementing-data-science-projects/)

# 向量嵌入：机器学习中的核心技术

- [Vector Embeddings Explained](https://opencv.org/blog/vector-embeddings/)
- 我用 AI 生成的一些推文资料，可以用于写作
  - [ChatGPT 对话](https://chatgpt.com/share/68640f38-2038-8005-9956-f6d1268d51a0)，我已经让 AI 生成了一些基本的文本，可以直接用于推文写作
  - [豆包写的](https://www.doubao.com/thread/wb1db3cecd9776070)
  
- 其它资料
  - [What are Vector Embeddings](https://www.pinecone.io/learn/vector-embeddings/)，图片可以引用
  - [什么是机器学习中的嵌入？](https://aws.amazon.com/what-is/embeddings-in-machine-learning/)
  - [Vector Embeddings for Developers: The Basics](https://www.pinecone.io/learn/vector-embeddings-for-developers/)，基础知识讲的比较清楚
  - [What are vector embeddings? A complete guide [2025]](https://www.meilisearch.com/blog/what-are-vector-embeddings)
  - [Multi-vector embeddings (ColBERT, ColPali, etc.)](https://weaviate.io/developers/weaviate/tutorials/multi-vector-embeddings)


# Local Projection：简介

这篇推文的任务是介绍 LP 的基本原理和相关理论基础，不涉及实操。 

- Jordà, ò. (2023). Local Projections for Applied Economics. Annual Review of Economics, 15(1), 607–631. [Link](https://doi.org/10.1146/annurev-economics-082222-065846), [PDF](http://sci-hub.ren/10.1146/annurev-economics-082222-065846), [Google](<https://scholar.google.com/scholar?q=Local Projections for Applied Economics>).
- Jordà, ò., & Taylor, A. M. (2025). Local Projections. Journal of Economic Literature, 63(1), 59–110. [Link](https://doi.org/10.1257/jel.20241521) (rep), [PDF](http://sci-hub.ren/10.1257/jel.20241521), [Appendix](https://www.aeaweb.org/doi/10.1257/jel.20241521.appx), [Google](<https://scholar.google.com/scholar?q=Local Projections>). [-Replication-](https://doi.org/10.3886/E208590V1), [github](https://github.com/ojorda/JEL-Code)
- Plagborg-Møller, M., & Wolf, C. K. (2021). Local Projections and VARs Estimate the Same Impulse Responses. Econometrica, 89(2), 955–980. [Link](https://doi.org/10.3982/ECTA17813) (rep), [PDF](http://sci-hub.ren/10.3982/ECTA17813), [Google](<https://scholar.google.com/scholar?q=Local Projections and VARs Estimate the Same Impulse Responses>).
- 这篇文章的 [Slides](https://static1.squarespace.com/static/5f4fc8d353469c7584b4f560/t/68124474927e6f6774afac60/1746027643504/DualLP+%288%29.pdf) 讲的蛮清楚的。
  - Coulombe, P. G., & Klieber, K. (2025). Opening the Black Box of Local Projections (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2505.12422) (rep), [PDF](https://arxiv.org/pdf/2505.12422.pdf), [Google](<https://scholar.google.com/scholar?q=Opening the Black Box of Local Projections (Version 1)>). [R codes](https://github.com/philgoucou/LPdecomposition), [Slides](https://static1.squarespace.com/static/5f4fc8d353469c7584b4f560/t/68124474927e6f6774afac60/1746027643504/DualLP+%288%29.pdf)
- 基本原理：Simon Lloyd, 2024, Introduction to Local Projections. Slides. [Link](https://splloyd-econ.github.io/Lloyd_CCBS_LP_Slides_2024.pdf)



## 软件实现

简要介绍在不同的软件中使用什么命令或 Packages 实现即可，无需展开。

只需要把 [Jordà, ò - local projections](https://sites.google.com/site/oscarjorda/home/local-projections?pli=1) 中的内容整理一下即可。 

### STATA code

-   STATA now has its own native command [lpirf](https://www.stata.com/manuals/tslpirf.pdf)

-   Replication code for all examples in the review article "[Local Projections](https://www.frbsf.org/research-and-insights/publications/working-papers/2024/08/local-projections/)" (joint with [Alan Taylor,](https://sites.google.com/view/amtaylor/home) forthcoming in the Journal of Economic Literature), is available here:

<https://github.com/ojorda/JEL-Code>

-   Replication code for all examples in the review article "[Inference for Local Projections](https://arxiv.org/abs/2306.03073)" (with Atsushi Inoue and Guido Kuersteiner, prepared for The Econometrics Journal), is available here:

<https://github.com/ojorda/Econometrics-Journal>

### Julia codes

- [Julia codes for Local projection](https://juliapackages.com/p/localprojections), [github](https://github.com/junyuan-chen/LocalProjections.jl)

### R code: package lpirfs

-   Code prepared by Philipp Adämmer. [Here is a description of its capabilities](https://cran.r-project.org/web/packages/lpirfs/lpirfs.pdf)


### MATLAB code
Silvia Miranda Agrippino's MATLAB code for "The Transmission of Monetary Policy Shocks" (with G. Ricco). 

-   [typical and Bayesian local projections available here](http://silviamirandaagrippino.com/code-data)

- replication code for "Impulse responses by smooth local projections" by Barnichon and Brownlees
  - [code from the Review and Economic Statistics publication available here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/8KQJBJ)

- [Simulation study of Local Projections, VARs, and related estimators](https://github.com/dake-li/lp_var_simul)




### Bayesian local projections

-   Amaze Lusompa has written a great paper on how to think about Bayesian local projections. [Check his research here](https://sites.google.com/uci.edu/amazelusompa/research)

### inference

-   [Mikkel Plagborg-Møller](https://mikkelpm.scholar.princeton.edu/) is doing great research on local projections. Check his papers here: <https://www.mikkelpm.com/research/>

### other applications of local projections

-   My colleague [Regis Barnichon](https://www.frbsf.org/our-people/economists/regis-barnichon/) has written a series of very interesting papers. Check his research here: <https://sites.google.com/site/regisbarnichon/>

### references

main reference: 

- Jordà, ò. (2005). Estimation and Inference of Impulse Responses by Local Projections. American Economic Review, 95(1), 161–182. [Link](https://doi.org/10.1257/0002828053828518) (rep), [PDF](http://sci-hub.ren/10.1257/0002828053828518), [Appendix](https://www.aeaweb.org/doi/10.1257/0002828053828518.appx), [Google](<https://scholar.google.com/scholar?q=Estimation and Inference of Impulse Responses by Local Projections>), [-cited-](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17126337218822101214,17923124496323615981)


### Review articles on local projections that provide an overview:

- Jordà, ò., & Taylor, A. M. (2025). Local Projections. Journal of Economic Literature, 63(1), 59–110. [Link](https://doi.org/10.1257/jel.20241521) (rep), [PDF](http://sci-hub.ren/10.1257/jel.20241521), [Appendix](https://www.aeaweb.org/doi/10.1257/jel.20241521.appx), [Google](<https://scholar.google.com/scholar?q=Local Projections>). [-Replication-](https://doi.org/10.3886/E208590V1), [github](https://github.com/ojorda/JEL-Code)
- Inoue, A., Jordà, ò., & Kuersteiner, G. M. (2025). Inference for local projections. The Econometrics Journal. [Link](https://doi.org/10.1093/ectj/utaf004), [PDF](http://sci-hub.ren/10.1093/ectj/utaf004), [Google](<https://scholar.google.com/scholar?q=Inference for local projections>). [github-Stata codes](https://github.com/ojorda/Econometrics-Journal), [Slides](https://www.jamelsaadaoui.com/wp-content/uploads/2025/01/slidesJorda.pdf)


## 参考文献- 
note: 这些文献，以及你写推文时新增的文献都要同一列在这里。

- Jordà, ò. (2023). Local Projections for Applied Economics. Annual Review of Economics, 15(1), 607–631. [Link](https://doi.org/10.1146/annurev-economics-082222-065846), [PDF](https://www.annualreviews.org/docserver/fulltext/economics/15/1/annurev-economics-082222-065846.pdf?expires=1752910574&id=id&accname=guest&checksum=55A163CF0E40FE7566BA2C55C7FE3B1A), [Google](<https://scholar.google.com/scholar?q=Local Projections for Applied Economics>).
- Jordà, ò., & Taylor, A. M. (2025). Local Projections. Journal of Economic Literature, 63(1), 59–110. [Link](https://doi.org/10.1257/jel.20241521) (rep), [PDF](http://sci-hub.ren/10.1257/jel.20241521), [Appendix](https://www.aeaweb.org/doi/10.1257/jel.20241521.appx), [Google](<https://scholar.google.com/scholar?q=Local Projections>). [-Replication-](https://doi.org/10.3886/E208590V1), [github](https://github.com/ojorda/JEL-Code)
- Plagborg-Møller, M., & Wolf, C. K. (2021). Local Projections and VARs Estimate the Same Impulse Responses. Econometrica, 89(2), 955–980. [Link](https://doi.org/10.3982/ECTA17813) (rep), [PDF](https://onlinelibrary.wiley.com/doi/epdf/10.3982/ECTA17813), [Google](<https://scholar.google.com/scholar?q=Local Projections and VARs Estimate the Same Impulse Responses>).
- Montiel Olea, J. L., & Plagborg-Møller, M. (2021). Local Projection Inference Is Simpler and More Robust Than You Think. Econometrica, 89(4), 1789–1823. [Link](https://doi.org/10.3982/ECTA18756) (rep), [PDF](http://sci-hub.ren/10.3982/ECTA18756), [Google](<https://scholar.google.com/scholar?q=Local Projection Inference Is Simpler and More Robust Than You Think>).
- Li, D., Plagborg-M?ller, M., & Wolf, C. K. (2024). Local projections vs. VARs: Lessons from thousands of DGPs. Journal of Econometrics, 244(2), 105722. [Link](https://doi.org/10.1016/j.jeconom.2024.105722), [PDF](https://arxiv.org/pdf/2104.00655.pdf), [Google](<https://scholar.google.com/scholar?q=Local projections vs. VARs: Lessons from thousands of DGPs>).
  - [Abstract](https://www.mikkelpm.com/research/#/) - [Published version](https://doi.org/10.1016/j.jeconom.2024.105722) (open access) - [Working paper](https://www.mikkelpm.com/files/lp_var_simul.pdf) - [Supplement](https://www.mikkelpm.com/files/lp_var_simul_supplement.pdf) - [Slides](https://www.mikkelpm.com/files/lp_var_simul_slides.pdf) - [Matlab code](https://github.com/dake-li/lp_var_simul) - [arXiv](https://arxiv.org/abs/2104.00655)


# 论文推介：揭开 Local Projections 的黑箱

Coulombe, P. G., & Klieber, K. (2025). Opening the Black Box of Local Projections (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2505.12422) (rep), [PDF](https://arxiv.org/pdf/2505.12422.pdf), [Google](<https://scholar.google.com/scholar?q=Opening the Black Box of Local Projections (Version 1)>). [R codes](https://github.com/philgoucou/LPdecomposition), [Slides](https://static1.squarespace.com/static/5f4fc8d353469c7584b4f560/t/68124474927e6f6774afac60/1746027643504/DualLP+%288%29.pdf)

## 简介

𝐎𝐩𝐞𝐧𝐢𝐧𝐠 𝐭𝐡𝐞 𝐁𝐥𝐚𝐜𝐤 𝐁𝐨𝐱 𝐨𝐟 𝐋𝐨𝐜𝐚𝐥 𝐏𝐫𝐨𝐣𝐞𝐜𝐭𝐢𝐨𝐧𝐬 is my new working paper with [Karin Klieber](https://www.linkedin.com/in/ACoAACf2uhgB0eGNrJA4fH3JrvYyilga7qroOt0). (paper: <https://lnkd.in/e8Z29EeJ>, deck: <https://lnkd.in/eGEUCJsr>).

Local projections are now routinely used to estimate impulse response functions (IRFs) in empirical macroeconomics. Yet in many ways, they are black boxes. The mechanisms behind the curves are often unclear. Perhaps most importantly: do the episodes we think are driving the causal effect estimates actually 𝘥𝘰 𝘴𝘰? Are those numerous enough to be confident about external validity?

We introduce a 𝗻𝗲𝘄 𝗱𝗲𝗰𝗼𝗺𝗽𝗼𝘀𝗶𝘁𝗶𝗼𝗻 of LP estimates that makes their historical foundation transparent. Each estimate is expressed as a sum of contributions from individual events---weights times observed responses---revealing how specific periods shape the average effect. We plot cumulative contributions over time, which converge by construction to the LP estimate at horizon 𝘩 (see figure below). We also visualize the weights as a time series and introduce LP concentration statistics to summarize how broad or narrow the evidence base is.

𝗧𝗵𝗲 𝗺𝗲𝗮𝗻𝗶𝗻𝗴(𝘀) 𝗼𝗳 𝘄𝗲𝗶𝗴𝗵𝘁𝘀. In linear local projections estimated via least squares, the weight series admits two interpretations. First, by a variation of the Frisch-Waugh-Lovell theorem, the weights can be viewed as purified and standardized shocks. Second, they are proximity scores, measuring the similarity between the projected intervention and past interventions in the sample.

𝗠𝗮𝗰𝗵𝗶𝗻𝗲 𝗟𝗲𝗮𝗿𝗻𝗶𝗻𝗴. The proximity-based interpretation of weights extends beyond linear models, as many machine learning (ML) algorithms generate IRFs that, while nonlinear in regressors, remain linear in the outcome variable. Proximity weights offer a common scale for comparing linear and ML-based LPs.

𝗘𝗺𝗽𝗶𝗿𝗶𝗰𝗮𝗹𝗹𝘆, we apply the method to various domains:

▶ 𝘔𝘰𝘯𝘦𝘵𝘢𝘳𝘺 𝘱𝘰𝘭𝘪𝘤𝘺: We find that Cholesky VAR shocks produce a price puzzle by misreading stagflation episodes from the 1970s. Romer and Romer (2004) shocks get the IRF sign right by offsetting this misinterpretation with a long stretch of monetary loosening shocks coinciding with the peak of late 1970s inflation. Random Forest refines the portrait by assigning elevated proximity weights only to well-known episodes of political interference with the Fed.

▶ 𝘍𝘪𝘴𝘤𝘢𝘭 𝘱𝘰𝘭𝘪𝘤𝘺: Ramey and Zubairy's (2018) state-dependent fiscal multipliers in recessions are driven almost entirely by a single event: World War II.

▶ 𝘊𝘭𝘪𝘮𝘢𝘵𝘦 𝘴𝘩𝘰𝘤𝘬𝘴: The long-run GDP impact of global temperature shocks in Bilal and Känzig (2024) appears fragile, primarily driven by the pairing of a single 1960s volcanic eruption and exceptional post-war growth.

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250719180429.png)

# 论文推介：LP与VARs的冲击反应函数：实操建议

Olea, J. L. M., Plagborg-M?ller, M., Qian, E., & Wolf, C. (2025). Local Projections or VARs? A Primer for Macroeconomists. National Bureau of Economic Research. [Link](https://doi.org/10.3386/w33871), [PDF](https://www.nber.org/system/files/working_papers/w33871/w33871.pdf), [-Appendix-](https://economics.mit.edu/sites/default/files/2025-03/lp_var_primer_supplement.pdf), [Google](<https://scholar.google.com/scholar?q=Local Projections or VARs? A Primer for Macroeconomists>).
- [Abstract](https://www.mikkelpm.com/research/#/) - [Working paper](https://www.mikkelpm.com/files/lp_var_primer.pdf) - [Supplement](https://www.mikkelpm.com/files/lp_var_primer_supplement.pdf) - [Matlab code](https://github.com/ckwolf92/lp_var_nberma) - [arXiv](https://arxiv.org/abs/2503.17144)


- What should applied macroeconomists know about local projection (LP) and vector autoregression (VAR) impulse response estimators? The two methods share the same estimand, but in finite samples lie on opposite ends of a bias-variance trade-off. While the low bias of LPs comes at a quite steep variance cost, this cost must be paid to achieve robust uncertainty assessments. Hence, when the goal is to convey what can be learned about dynamic causal effects from the data, VARs should only be used with long lag lengths, ensuring equivalence with LP. For LP estimation, we provide guidance on selection of lag length and controls, bias correction, and confidence interval construction.


# 论文复现：Local Projection 的 8 个应用

简要介绍 Local Projection 的原理。   
重点在于：复现这篇文章中介绍的 8 个 Examples 的 Stata 实操：[-Replication-](https://doi.org/10.3886/E208590V1)。

- Jordà, ò., & Taylor, A. M. (2025). Local Projections. Journal of Economic Literature, 63(1), 59–110. [Link](https://doi.org/10.1257/jel.20241521) (rep), [PDF](http://sci-hub.ren/10.1257/jel.20241521), [Appendix](https://www.aeaweb.org/doi/10.1257/jel.20241521.appx), [Google](<https://scholar.google.com/scholar?q=Local Projections>). [-Replication-](https://doi.org/10.3886/E208590V1), [github](https://github.com/ojorda/JEL-Code)


## Stata 实操

代码和数据：[-Replication-](https://doi.org/10.3886/E208590V1), [github](https://github.com/ojorda/JEL-Code)

Folder name: Output figures shown in the paper

- Example1\_LongDifferences: Figure1a.pdf, Figure1b.pdf
- Example2\_Multipliers: Figure2a.pdf, Figure2b.pdf, Figure9a.pdf, Figure9b.pdf
- Example3\_Smoothing: Figure3.pdf
- Example4\_LagAugmentation: Figure4.pdf
- Example5\_SignificanceBands: Figure5a.pdf, Figure5b.pdf
- Example6\_JointInference: Figure6a.pdf, Figure6b.pdf
- Example7\_MinimumDistance: Figure7a.pdf, Figure7b.pdf, Figure7c.pdf, Figure7d.pdf
- Example8\_Counterfactuals: Figure8a.pdf, Figure8b.pdf
- Example9\_StateDependence: Figure10a.pdf, Figure10b.pdf

The STATA programs rely on various packages which need to be installed for the code to run. If an error message occurs, search for and install the required package. In addition, correct output of the figures requires the fonts Palatino and cmsy10 to be installed. Most do files can be run individually, but some folders also include an all.do file which will run all programs in that folder. Each do file sets the current directory and users will need to amend those lines to point to their own directory path.

### 需要安装的外部命令

```stata
ssc install estout
ssc install ivreg2
ssc install xtscc
ssc install sxpose
ssc install lpdid
ssc install xtivreg28
ssc install freduse
ssc install egenmore
ssc install outreg2
ssc install boottest
ssc install levelsof
ssc install ranktestto
ssc install matselrc
```

# 论文复现-Stata：LP 的统计推断

- Inoue, A., Jordà, ò., & Kuersteiner, G. M. (2025). Inference for local projections. The Econometrics Journal. [Link](https://doi.org/10.1093/ectj/utaf004), [PDF](http://sci-hub.ren/10.1093/ectj/utaf004), [Google](<https://scholar.google.com/scholar?q=Inference for local projections>). [github-Stata codes](https://github.com/ojorda/Econometrics-Journal), [Slides](https://www.jamelsaadaoui.com/wp-content/uploads/2025/01/slidesJorda.pdf)


## Stata 复现

The "Replication Code" zip file contains the STATA code used in the paper "Inference for Local Projections" by Atsushi Inoue, Oscar Jorda and Guido Kuersteiner. The folder contains the following files:

1.  `Figure1.do` Compares Newey-West bands with LP-FGLS as in Lusompa (2023, Quantitative Economics)
2.  `Figure2.do` Compares Newey-West bands with Lag-Augmented bands as in Montiel-Olea and Plagborg-Moller (2021 Econometrica)
3.  `Figure3.do` Compares Newey-West bands with sup-t bands as in Montiel-Olea and Plagborg-Moller (2019 Journal of Applied Econometrics)
4.  `Figure4.do` Empirical example using significance bands on the response of shelter PCE inflation to a monetary shock using Bauer and Swanson (2023 NBER Macro Annual)
5.  `Figure5.do` Monte Carlo exercises showing the probability coverage of significance bands
6.  `sigband_shelterinf.dta` Dataset for Figure 4 The naming convention follows that of the figures in the paper.


## 论文复现-Stata：

Kolesár, M., & Plagborg-M?ller, M. (2025). Dynamic Causal Effects in a Nonlinear World: the Good, the Bad, and the Ugly. *Journal of Business & Economic Statistics*, 2025, accepted. [Link](https://doi.org/10.48550/arXiv.2411.10415), [PDF](https://arxiv.org/pdf/2411.10415.pdf), [Google](<https://scholar.google.com/scholar?q=Dynamic Causal Effects in a Nonlinear World: the Good, the Bad, and the Ugly>). [Stata code](https://github.com/mikkelpm/nonlinear_dynamic_causal)  
- [Abstract](https://www.mikkelpm.com/research/#/) - [Working paper](https://www.mikkelpm.com/files/nonlinear_causal.pdf) - [Supplement](https://www.mikkelpm.com/files/nonlinear_causal_supplement.pdf) - [Slides](https://www.mikkelpm.com/files/nonlinear_causal_slides.pdf) - [Rejoinder to discussants](https://www.mikkelpm.com/files/nonlinear_causal_rejoinder.pdf) - [Stata code](https://github.com/mikkelpm/nonlinear_dynamic_causal) - [arXiv](https://arxiv.org/abs/2411.10415)

# lpirfs - Local Projection：R package

介绍该方法的原理和 R 实现。

- 理论部分以 [PDF](https://journal.r-project.org/articles/RJ-2019-052/RJ-2019-052.pdf) 为基础。原始理论源于[Jordà (2005)](https://www.aeaweb.org/articles?id=10.1257/0002828053828518).
- 实操部分参见 [Replications and applications with lpirfs](https://cran.r-project.org/web/packages/lpirfs/vignettes/lpirfs_vignette.html) ([source](https://cran.r-project.org/web/packages/lpirfs/vignettes/lpirfs_vignette.Rmd), [R code](https://cran.r-project.org/web/packages/lpirfs/vignettes/lpirfs_vignette.R)) 

Adämmer, P. (2019). lpirfs: An R Package to Estimate Impulse Response Functions by Local Projections. The R Journal, 11(2), 421. [Link](https://doi.org/10.32614/rj-2019-052), [PDF](https://journal.r-project.org/articles/RJ-2019-052/RJ-2019-052.pdf), [Google](<https://scholar.google.com/scholar?q=lpirfs: An R Package to Estimate Impulse Response Functions by Local Projections>), [-cited-](https://scholar.google.com/scholar?cites=2592261158201323897&as_sdt=2005&sciodt=0,5&hl=zh-CN), [github](https://github.com/AdaemmerP/lpirfs), [Help Document](https://cran.r-project.org/web/packages/lpirfs/lpirfs.pdf)
- Examples and replicates empirical results to show how to use the R-package lpirfs. [-Link-](https://adaemmerp.github.io/lpirfs/README_docs.html)

Load data from package to estimate a simple, new-Keynesian, closed-economy model. These data are used by [Jordà (2005)](https://www.aeaweb.org/articles?id=10.1257/0002828053828518) in chapter IV, p. 174. See the data's help file in the package or the [paper](https://www.aeaweb.org/articles?id=10.1257/0002828053828518) for a detailed description of the data.

## 参考文献

- Adämmer, P. (2019). lpirfs: An R Package to Estimate Impulse Response Functions by Local Projections. The R Journal, 11(2), 421. [Link](https://doi.org/10.32614/rj-2019-052), [PDF](https://journal.r-project.org/articles/RJ-2019-052/RJ-2019-052.pdf), [Google](<https://scholar.google.com/scholar?q=lpirfs: An R Package to Estimate Impulse Response Functions by Local Projections>), [-cited-](https://scholar.google.com/scholar?cites=2592261158201323897&as_sdt=2005&sciodt=0,5&hl=zh-CN), [github](https://github.com/AdaemmerP/lpirfs), [Help Document](https://cran.r-project.org/web/packages/lpirfs/lpirfs.pdf)
- Jordà, ò. (2005). Estimation and Inference of Impulse Responses by Local Projections. American Economic Review, 95(1), 161–182. [Link](https://doi.org/10.1257/0002828053828518) (rep), [PDF](http://sci-hub.ren/10.1257/0002828053828518), [Appendix](https://www.aeaweb.org/doi/10.1257/0002828053828518.appx), [Google](<https://scholar.google.com/scholar?q=Estimation and Inference of Impulse Responses by Local Projections>).


# 论文推介：会计研究中的结构模型

工作量：两篇推文

Bertomeu, Jeremy and Liang, Ying and Marinovic, Ivan, A Primer on Structural Estimation in Accounting Research (January 24, 2023). Stanford University Graduate School of Business Research Paper No. 4336916, Olin Business School Center for Finance & Accounting Research Paper No. 2023/01, Available at SSRN: https://ssrn.com/abstract=4336916 or http://dx.doi.org/10.2139/ssrn.4336916


# pyfixest-Python包：检验TWFE是否导致了严重的偏误

Lal, A. (2025). When can we get away with using the two-way fixed effects regression? (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2503.05125) (rep), [PDF](https://arxiv.org/pdf/2503.05125.pdf), [Google](<https://scholar.google.com/scholar?q=When can we get away with using the two-way fixed effects regression? (Version 1)>), [github](https://github.com/apoorvalal/TestingInEventStudies), [pyfixest](https://github.com/py-econometrics/pyfixest).

The use of the two-way fixed effects regression in empirical social science was historically motivated by folk wisdom that it uncovers the Average Treatment effect on the Treated (ATT) as in the canonical two-period two-group case. This belief has come under scrutiny recently due to recent results in applied econometrics showing that it fails to uncover meaningful averages of heterogeneous treatment effects in the presence of effect heterogeneity over time and across adoption cohorts, and several heterogeneity-robust alternatives have been proposed. However, these estimators often have higher variance and are therefore under-powered for many applications, which poses a bias-variance tradeoff that is challenging for researchers to navigate. In this paper, we propose simple tests of linear restrictions that can be used to test for differences in dynamic treatment effects over cohorts, which allows us to test for when the two-way fixed effects regression is likely to yield biased estimates of the ATT. These tests are implemented as methods in the `pyfixest` python library.




# DDML简介-写得非常易懂

- [Lab 2: Estimating causal effects using double machine learning](https://ml-in-econ.appspot.com/lab2.htmlhttps://ml-in-econ.appspot.com/lab2.html)


# Bootstrap 趣味图解

- [Bootstrap Animations](https://www.stat.auckland.ac.nz/~wild/BootAnim/)

![bootstrap1](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/bootstrap1.gif)

# openCV 平台介绍

[opencv.org](https://opencv.org/ "https://opencv.org")
- [github](https://github.com/opencv/opencv)
- [tutorial](https://docs.opencv.org/4.x/d9/df8/tutorial_root.html)


# Stata 新命令：attcic - 

`attcic` implements the CiC attrition corrections proposed in Ghanem et al. (J of Econometrics, 2024). These corrections exploit baseline outcome data to recover the ATT-R, ATE-R, and ATE, and can be applied to randomized experiments as well as quasi-experimental difference-in-difference designs. In addition to these corrections, `attcic` also reports the results of comparator approaches such as the IPW corrections, Manski bounds, and Lee bounds.

Ghanem, D., Hirshleifer, S., Kédagni, D., Ortiz-Becerra, K. (2024b). Correcting Attrition Bias using Changes-in-Changes. Journal of
        Econometrics.


# Stata 新命令：xttacce - Time Averaged Common Correlated Effects estimator (TACCE) for fixed-N panel data and SUR

- Westerlund, J., Kaddoura, Y., and Karavias, Y., 2025. Time Averaged CCE. http://dx.doi.org/10.2139/ssrn.5274776

# 论文推介：引力模型-估计方法和实操建议

Larch, M., Shikher, S., & Yotov, Y. V. (2025). Estimating Gravity Equations: Theory Implications, Econometric Developments, and?Practical Recommendations. Review of International Economics. Portico. [Link](https://doi.org/10.1111/roie.12789), [PDF](https://onlinelibrary.wiley.com/doi/epdf/10.1111/roie.12789), [Google](<https://scholar.google.com/scholar?q=Estimating Gravity Equations: Theory Implications, Econometric Developments, and?Practical Recommendations. Review of International Economics>).


# 论文推介：大牛综述：DDML-双重/去偏机器学习模型简介

作者提供了 <https://dmlguide.github.io/> 主页：

On this website, you will find

-   replication materials,
-   illustrations on how to implement DML in both R and Stata,
-   references to resources related to DML.

这个网站介绍的通俗易懂，因此，整个推文可以通过整理和翻译这个网站的内容来实现。   

> Ahrens, A., Chernozhukov, V., Hansen, C., Kozbur, D., Schaffer, M., & Wiemann, T. (2025). An Introduction to Double/Debiased Machine Learning (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2504.08324) (rep), [PDF](https://arxiv.org/pdf/2504.08324.pdf), [Google](<https://scholar.google.com/scholar?q=An Introduction to Double/Debiased Machine Learning (Version 1)>).

- This paper provides a practical introduction to Double/Debiased Machine Learning (DML). DML provides a general approach to performing inference about a target parameter in the presence of nuisance parameters. The aim of DML is to reduce the impact of nuisance parameter estimation on estimators of the parameter of interest. We describe DML and its two essential components: Neyman orthogonality and cross-fitting. We highlight that DML reduces functional form dependence and accommodates the use of complex data types, such as text data. We illustrate its application through **three empirical examples** that demonstrate DML's applicability in cross-sectional and panel settings.

## 参考资料

### Textbooks treatments covering DML

-   Chernozhukov, V. & Hansen, C. & Kallus, N. & Spindler, M. & Syrgkanis, V. (2024): *Applied Causal Inference Powered by ML and AI*. <https://causalml-book.org/>.
-   Huber, Martin (2023). *Causal analysis: Impact evaluation and Causal Machine Learning with applications in R*. MIT Press.
-   Hernán MA, Robins JM (2020). *Causal Inference: What If*. Boca Raton: Chapman & Hall/CRC

### Software packages implementing DML

-   `ddml` for Stata by Ahrens, Hansen, Schaffer, Wiemann (2024).
    -   [Package tutorials](https://statalasso.github.io/)
    -   Ahrens A, Hansen C B, Schaffer M E, Wiemann T (2024). ddml: Double/debiased machine learning in Stata. *Stata Journal*. 24(1): 3-45. <https://doi.org/10.1177/1536867X2412336>
-   `ddml` for R by Wiemann, Ahrens, Hansen, Schaffer (2024).
    -   [Package vignette](https://thomaswiemann.com/ddml/)
-   `DoubleML` for R and Python.
    -   The [package website](https://docs.doubleml.org/) provides extensive tutorials.
    -   Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M. (2022). DoubleML - An Object-Oriented Implementation of Double Machine Learning in Python. *Journal of Machine Learning Research*. 23(53): 1-6, <https://www.jmlr.org/papers/v23/21-0862.html>.
    -   Bach, P., Chernozhukov, V., Kurz, M. S., Spindler, M. and Klaassen, S. (2024), DoubleML - An Object-Oriented Implementation of Double Machine Learning in R. *Journal of Statistical Software*. 108(3): 1-56. <https://www.jstatsoft.org/article/view/v108i03>
-   `EconML` for Python, see [module website](https://econml.azurewebsites.net/)
-   `CausalELM` for Julia includes a DML program, see [website](https://dscolby.github.io/CausalELM.jl/stable/)


### Other online tutorials

-   The online tutorial accompanying Mogstad & Torgovitsky (["Instrumental Variables with Heterogeneous Treatment Effects,"](https://a-torgovitsky.github.io/ivhandbook.pdf) 2024, *Handbook of Labor Economics*) includes a demonstration of how to use DML for the estimation of Local Average Treatment Effects and Average Causal Responses.

### Video lectures

-   Victor Chernozhukov, ["Double Machine Learning for Causal and Treatment Effects"](https://www.youtube.com/watch?v=eHOjmyoPCFU).

### References on supervised machine learning

*Textbooks:*

-   James, G, Witten, Daniela, Hastie, Trevor & Tibshirani, R (2023). An Introduction to Statistical Learning with Applications in R. <https://www.statlearning.com/>
-   Hastie, Trevor, Robert Tibshirani, Jerome H. Friedman, and Jerome H. Friedman. The elements of statistical learning: data mining, inference, and prediction. Vol. 2. New York: springer, 2009. <https://hastie.su.domains/ElemStatLearn/>

*Review papers:*

-   Melissa Dell, Deep Learning for Economists, <https://arxiv.org/abs/2407.15339>
-   Athey, Susan, and Guido W. Imbens. 2019. Machine Learning Methods That Economists Should Know About. *Annual Review of Economics*. 11(Volume 11, 2019): 685--725. <https://doi.org/10.1146/annurev-economics-080217-053433>

Other references
----------------

Ahrens, A., Hansen, C.B., Schaffer, M.E. and Wiemann, T. (2025). Model Averaging and Double Machine Learning. *Journal of Applied Econometrics*. <https://doi.org/10.1002/jae.3103>

Ahrens A, Hansen C B, Schaffer M E, Wiemann T (2024). ddml: Double/debiased machine learning in Stata. *Stata Journal*. 24(1), 3-45. <https://doi.org/10.1177/1536867X2412336>

Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M. (2022). DoubleML - An Object-Oriented Implementation of Double Machine Learning in Python. *Journal of Machine Learning Research*. 23(53), 1-6. <https://www.jmlr.org/papers/v23/21-0862.html>

Bach, P., Chernozhukov, V., Kurz, M. S., Spindler, M. and Klaassen, S. (2024), DoubleML - An Object-Oriented Implementation of Double Machine Learning in R. *Journal of Statistical Software*. 108(3), 1-56. <https://www.jstatsoft.org/article/view/v108i03>

Callaway, B., & Sant'Anna, P. H. (2021). Difference-in-differences with multiple time periods. *Journal of econometrics*, 225(2), 200-230. <https://doi.org/10.1016/j.jeconom.2020.12.001>

Dobkin, Carlos, Amy Finkelstein, Raymond Kluender, and Matthew J. Notowidigdo. 2018. The Economic Consequences of Hospital Admissions. *American Economic Review* 108 (2), 308--52.

Paola Giuliano, Nathan Nunn, Understanding Cultural Persistence and Change, *The Review of Economic Studies*. 88(4), 1541--1581. <https://doi.org/10.1093/restud/rdaa074>

Poterba, J. M., Venti, S. F., & Wise, D. A. (1995). Do 401 (k) contributions crowd out other personal saving?. *Journal of Public Economics*, 58(1), 1-32.

Sant'Anna, P. H., & Zhao, J. (2020). Doubly robust difference-in-differences estimators. *Journal of econometrics*, 219(1), 101-122.

Sun, L., & Abraham, S. (2021). Estimating dynamic treatment effects in event studies with heterogeneous treatment effects. *Journal of econometrics*. 225(2), 175-199.


# 论文推介：AER-线性回归中的组合偏差问题

工作量：两篇推文。

Goldsmith-Pinkham, P., Hull, P., & Kolesár, M. (2024). Contamination Bias in Linear Regressions. American Economic Review, 114(12), 4015–4051. [Link](https://doi.org/10.1257/aer.20221116) (rep), [PDF](http://sci-hub.ren/10.1257/aer.20221116), [Appendix](https://www.aeaweb.org/doi/10.1257/aer.20221116.appx), [-Appendix-](https://www.aeaweb.org/articles/materials/22031), [Google](<https://scholar.google.com/scholar?q=Contamination Bias in Linear Regressions>), [-Replication-Stata+R codes](https://doi.org/10.3886/E207983V1), 

任务：

- 写一篇论文推介，介绍该文的核心观点，主要研究内容和结论
- 做一个论文复现报告，确保复现论文中的主要表格

# awesome-datascience

- <https://github.com/academic/awesome-datascience>
- An awesome Data Science repository to learn and apply for real world problems.

# Boosting 和 Bagging 的区别


# 论文推介：校准参数的标准误如何算？

Cocci, M. D., & Plagborg-Møller, M. (2024). Standard Errors for Calibrated Parameters. Review of Economic Studies. [Link](https://doi.org/10.1093/restud/rdae099) (rep), [PDF](https://watermark.silverchair.com/rdae099.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA2swggNnBgkqhkiG9w0BBwagggNYMIIDVAIBADCCA00GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMe7vG-3wIDqslnJ9yAgEQgIIDHvwF8O9L4uP2NBbPMSRGwH0rZ6Jh1zKRvlbRWljjy3qTIXY4PBdvvyMWxOFxB1hBH-7eubiMmCf6kqGYD8BSCsi_10rVnLlsIZh-UeIJdrYvgTrLuulmzYeSJrrKrCFdQzzipVjR_iJwDo0_MvmgNMNcbErvNLbYMK3A03nrwbXsKuRhSS3F4Hr04Rp826z4xZbJ9ajOmugTVcNCeQv6fUGCrB75IClLLfxbIqC0J_kdXsyoz0TYQsg6WnHXQ0sIfIKAjvrw4321CfvXLmo3iF13Wc-szrZJWlRL49yO6aLNo3INzcf2UsIglSRDfZ6rDccuH57E_3dS5bsP7SNDTggt7wV8_EfTeO-jiSG4WQcsXXrRuqFXV5GCmxzT6sgisDv5GDyqrvJNpBD4udMLjGz9AWwrS_zAqaj1X07FSnG2Stkd6iuwng4dR51OQ0OZ-CF2WpQ_4hS92fYVGl_Ri8P9cZiEaNrKVyAHuGU6DI2fFhbeqMsDzaddwikO9MKbh0iq2K-QBV3I0LVwlw2SNc_HIVj4_d18vFMBzN7mINUMFYMFHCF0_LUjKFZtX5_h2147_SVL_VK3fDn8ihNnwAu3PMjqtRkTUSYp7iapWl3mOodmVJLCP3NEMshKlyW83lADo_Tvfv9jid6-2k8I2NP3QWgzK2FVN_r3PMOYpz-3zRcUh7E3yd05FBCzSfC6zLU9O8e14_37sesKhVAgpfCETaRS-2aJ-dXKvN3CzvFBMt1-Mohm2cBv2nG_fw9pILLgOTyEmERktMw6aJyYoOO3iL9GGZnQGVma-0GHRdt-0ifu-S4sMG7iOy_NYWhbLqXTe-qH_MuOfM0Xn-UmBha745tseIhSXBwf-nuQ5-_bUeWRAD_D3vKSeFsVf40Gy1BmQeOMTVKFq06Kkvx9Ga_vqQuryHM83N2L8QjOScyaGEE7MnWE3LkxHoLQt97LP-CQ-g4eWBi16pEx77ryHKE7OSCCmx-XN2-QUmImZD6BzhFINbm3Wi2HGaFW0dYUSI2kUcW9zNUe2y9XRYvbtag5nS6kQ6yg2vi3KK-ccQ), [-PDF-](https://www.mikkelpm.com/files/calibration.pdf), [Google](<https://scholar.google.com/scholar?q=Standard Errors for Calibrated Parameters>). [-Replication: Python and MATLAB codes](https://zenodo.org/records/12784903), 

- 摘要：校准作为通过选定结构模型参数以匹配特定经验矩的方法，本质上可视为一种最小距离估计；这类估计量的现有标准误计算公式通常需要先获得经验矩相关结构的一致估计，但这在实际操作中往往难以实现，而单个经验矩的方差却通常较易估算。本文仅利用这些方差推导出了结构参数的保守标准误和置信区间，即便在最不理想的相关结构下这些结果依然有效；在模型存在过度识别的情况下，我们发现通过矩加权方案最小化最不利情形下估计量方差的问题，实则等价于一个具有简单答案的矩选择问题，最后还提出了针对过度识别限制或参数限制的检验方法，并将这些方法实证应用于多产品企业的菜单成本定价模型和异质性代理人新凯恩斯模型。 


# 机器学习仓库：

> <https://github.com/trekhleb/homemade-machine-learning>

![20250624113140](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250624113140.png)

# just-the-docs - 制作个人主页-轻量级文档生成工具

参考 [Focus on writing good documentation](https://just-the-docs.github.io/just-the-docs/)


# Python 练手数据文件汇总

- [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/)
  - [ucimlrepo package](https://github.com/uci-ml-repo/ucimlrepo)

# 论文推介：坏控制变量在 DDML 中危害很大

- Hünermund, P., Louw, B., & Caspi, I. (2023). Double machine learning and automated confounder selection: A cautionary tale. Journal of Causal Inference, 11(1). [Link](https://doi.org/10.1515/jci-2022-0078), [PDF](https://www.degruyterbrill.com/document/doi/10.1515/jci-2022-0078/pdf?licenseType=open-access), [Google](<https://scholar.google.com/scholar?q=Double machine learning and automated confounder selection: A cautionary tale>).

# 论文推介：

Doutreligne, M., & Varoquaux, G. (2025). How to select predictive models for decision-making or causal inference. GigaScience, 14. [Link](https://doi.org/10.1093/gigascience/giaf016), [PDF](https://watermark.silverchair.com/giaf016.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA4wwggOIBgkqhkiG9w0BBwagggN5MIIDdQIBADCCA24GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM5iM9hkWQtZwwhEvAAgEQgIIDP2lzki5fhc6qB4FaN5dNPiJ0zrcWlirsiNlmzzdM8NmFaloGHJxWixIRd7WH4F8jM9YlldyPhp853Mcmi6hduXDsgnUjwa1FhAcItT3hZLJRBqGBsnxj2IQnu2YhyOPadEvCIbt6R07PLMAV8wPR0ZbdQvURdbjhf3LwdaaCNewGQpDSGPVFNsdOTusbuFAUjV62E0gy0t75qox7gji477WQ0RsGQ-t-PYh2EsR8e_s9kEt3xytLIAF66AtJyWpbJzac3XIywJ-mZAmBQZNyMvl0JZpffV1ZiGJm47PwEwB8F5iLsFNcoIr3RyNpUD_vQNw9FMEWRnrT848VAHqDoidfXXIUcmkAOfCWvuVzpbOvaWVBqq_9oaqnuHKYCw_k-WbAlFlNCrrvTfKdu-CzdxvuSkuXRQu7KC-qgF3s0tL2eerj_e_VEUyApw790MQkriG3YqukwXTo1t_QryulKlvh7rUcYgYzwshv89BTRKDPlJilMrUvDD7bXDCDWcoUKNqfisXHXexrh9MMq5KooSXgU_1FpT2fb9C5c8KG5o7WGBHqHL-XexGdWQON6_j_o7s8x6idZPabPiGD0DzHey8PZ-xmnLK9hUsXfFAEoyqGL7aBxUkgSTz1zKA6JOpBVcRKEMWmKhmdkzdluShOFDoZ26KGk0id2zYLMhoz6xlLs2G84CHeEnbkh9Sl-PkI_AL0OBylmsZ5bZptaa6Du0_SxVwuqVH1CD30pakQROp9_GMkRBoiavmfrj6JteDozj33JMH-6zocfENEMhxtfM8WOrSPIZ5fUoqUHFnUsTe20LHwmT_NmEV9CiN5bPMxrURzBfilQ-ern-RJItZAaNzd5H1AON4cQo5u2xVdfXUwxWFzXV_89tgXZnRxdX7-cGBAFHGdCMFvld-BUi1_yqDOjO1uRp9PNhqklg0S1X2xy0PeN49b6HpzBMMQENEpWcx7ffGZViaKH6aDHyj1cKbW0Im_4YJorns0HBvKRwrOB273jNmicGgEVUN1dIIc8QGIdbGz-fCqOhLJHrO0uUCPvldSyExIjVQdvPvLlvx4CAF7O_Spvhsqbrdv4HG5_z-QNV66NzSnxSM_YDpj3A), [Google](<https://scholar.google.com/scholar?q=How to select predictive models for decision-making or causal inference>).

# 论文推介：DDML 简介

Ahrens, A., Chernozhukov, V., Hansen, C., Kozbur, D., Schaffer, M., & Wiemann, T. (2025). An Introduction to Double/Debiased Machine Learning. arXiv. [Link](https://doi.org/10.48550/arXiv.2504.08324) (rep), [PDF](https://arxiv.org/pdf/2504.08324.pdf), [Google](<https://scholar.google.com/scholar?q=An Introduction to Double/Debiased Machine Learning (Version 1)>).

# 论文复现 + 中文精要：R codes

> 这是三篇推文的工作量

- D’haultfœuille, X., Gaillac, C., & Maurel, A. (2025). Partially Linear Models under Data Combination. Review of Economic Studies, 92(1), 238–267. [Link](https://doi.org/10.1093/restud/rdae022) (rep), [PDF](http://sci-hub.ren/10.1093/restud/rdae022), [Google](<https://scholar.google.com/scholar?q=Partially Linear Models under Data Combination>). [-Replication-](https://zenodo.org/records/10230839) 

  - 我们研究了部分线性模型中结果变量与部分协变量分属两个独立数据集（无法匹配）的情况，这类数据组合问题在实证微观经济学中十分常见。借助最优传输理论的最新工具，我们对尖锐识别集进行了构造性刻画，并据此开发了一种新的推断方法。该方法利用识别集的几何特性，在有限样本下表现良好且易于操作。我们将此方法应用于 1850-1930 年美国代际收入流动性研究，结果显示：相比以往研究，新方法放宽了排他性约束，同时能给出有效置信区间。这种框架为跨数据集因果推断提供了实用方案，尤其适用于因数据隐私等限制无法合并数据集的场景。

# Statistical control requires causal justification

- Wysocki, A. C., Lawson, K. M., & Rhemtulla, M. (2022). Statistical Control Requires Causal Justification. Advances in Methods and Practices in Psychological Science, 5(2). [Link](https://doi.org/10.1177/25152459221095823), [PDF](https://journals.sagepub.com/doi/epdf/10.1177/25152459221095823), [Google](<https://scholar.google.com/scholar?q=Statistical Control Requires Causal Justification>).

  - 在相关研究或准实验研究中，常见的做法是通过统计控制消除回归系数中的混杂效应。控制相关混杂因素能够消除预测变量对结果变量的因果效应估计偏差——即令回归系数估计值更接近真实因果效应值。但统计控制仅在理想条件下有效。当选取的控制变量不恰当时，控制操作反而可能导致比未控制时更大的估计偏差。尽管统计控制在已发表的回归分析中普遍存在，且控制不恰当的第三方变量会产生严重后果，但控制变量的选择依据在文献中却很少明确说明。我们主张：研究者必须提出并论证包含结果变量、预测变量及潜在混杂因素的因果结构框架，才能严谨地选取合适的控制变量。通过演示回归系数如何因控制恰当/不恰当变量而产生变化，我们强调了因果性在控制变量选择中的核心地位。最后，为希望采用统计控制方法的实践研究者提供了具体建议。

# 面板数据的使用

- Cerqua, A., Letta, M., & Pinto, G. (2024). On the (Mis)Use of Machine Learning with Panel Data (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2411.09218) (rep), [PDF](https://arxiv.org/pdf/2411.09218.pdf), [Google](<https://scholar.google.com/scholar?q=On the (Mis)Use of Machine Learning with Panel Data (Version 2)>). [github](https://github.com/gabrielepinto/results_ml_replication), [ML_analysis_panel_data_replication.ipynb](https://github.com/gabrielepinto/results_ml_replication/blob/main/ML_analysis_panel_data_replication.ipynb)

# 

Frey, E. (2024). How to cross-validate your panel data in Python. Towards Data Science. Available
at : https://github.com/4Freye/panelsplit.

# staggered

- <https://psantanna.com/files/Roth_SantAnna_Staggered.pdf>
- <https://github.com/mcaceresb/stata-staggered>

# R package: unitdid

The `unitdid` package provides a set of functions for the analysis of the unit-level event studies (ULES) ([Arkhangelsky, Yanagimoto, and Zohar 2024](https://arxiv.org/abs/2403.19563)).

- Arkhangelsky, D., Yanagimoto, K., & Zohar, T. (2024). On Causal Inference with Model-Based Outcomes (Version 3). arXiv. [Link](https://doi.org/10.48550/arXiv.2403.19563) (rep), [PDF](https://arxiv.org/pdf/2403.19563.pdf), [Google](<https://scholar.google.com/scholar?q=On Causal Inference with Model-Based Outcomes (Version 3)>).
- R codes: <https://kazuyanagimoto.com/unitdid/>
- https://github.com/kazuyanagimoto/unitdid/
- https://tomzohar.com/assets/writeups/unitdid.pdf

# ecic: Extended changes-in-changes

- https://github.com/frederickluser/ecic
- frederickluser.github.io/ecic/


# 小样本下的 DID 统计推断问题

Mizushima, Yuji and Powell, David, Inference with Modern Difference-in-Differences Methods (April 04, 2025). Available at SSRN: https://ssrn.com/abstract=5221387 or http://dx.doi.org/10.2139/ssrn.5221387

### Abstract

Several new difference-in-differences (DiD) estimators address biases arising from staggered adoption and heterogeneous treatment effects. The reliability of the standard errors of these methods is understudied, particularly in settings with few treated units. This paper examines the finite-sample performance of seven leading DiD estimators under various simulated conditions. Most estimators tend to over-reject when the number of treated units is small. Treatment heterogeneity induces its own bias, reducing rejection rates. An imputation-based estimator paired with a wild bootstrap performs well across simulation designs, maintaining rejection rates close to nominal levels when there is treatment homogeneity and providing conservative inference otherwise.

**Keywords:** Difference-in-Differences, Wild Bootstrap, Finite Inference

# Python-pyfixest：

- Lal, A. (2025). When can we get away with using the two-way fixed effects regression? (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2503.05125) (rep), [PDF](https://arxiv.org/pdf/2503.05125.pdf), [Google](<https://scholar.google.com/scholar?q=When can we get away with using the two-way fixed effects regression? (Version 1)>).
  - The use of the two-way fixed effects regression in empirical social science was historically motivated by folk wisdom that it uncovers the Average Treatment effect on the Treated (ATT) as in the canonical two-period two-group case. This belief has come under scrutiny recently due to recent results in applied econometrics showing that it fails to uncover meaningful averages of heterogeneous treatment effects in the presence of effect heterogeneity over time and across adoption cohorts, and several heterogeneity-robust alternatives have been proposed. However, these estimators often have higher variance and are therefore under-powered for many applications, which poses a bias-variance tradeoff that is challenging for researchers to navigate. In this paper, we propose simple tests of linear restrictions that can be used to test for differences in dynamic treatment effects over cohorts, which allows us to test for when the two-way fixed effects regression is likely to yield biased estimates of the ATT. These tests are implemented as methods in the pyfixest python library.
- Python 实现：
  - [Getting Started with PyFixest](https://py-econometrics.github.io/pyfixest/quickstart.html)
  - [github-pyfixest](https://github.com/py-econometrics/pyfixest)


# Python 仓库介绍：pyfixest

- [py-econometrics/pyfixest](https://github.com/py-econometrics/pyfixest), [website](https://py-econometrics.github.io/pyfixest/pyfixest.html)


# 翻译 + 适当补充：Tidy Fixed Effects Regressions: fixest vs pyfixest

- [Tidy Fixed Effects Regressions: fixest vs pyfixest](https://blog.tidy-intelligence.com/posts/fixed-effects-regressions/)


# 翻译：Interactive Data Visualization with Python

- [Interactive Data Visualization with Python](https://blog.tidy-intelligence.com/posts/interactive-data-visualization-with-python/)


# python-wildboottest

- [python module for wild cluster bootstrapping](https://github.com/py-econometrics/wildboottest)
- [website](https://py-econometrics.github.io/wildboottest/)

# R 包推荐：wildrwolf

Romano-Wolf p-value adjustments for multiple hypotheses testing via the wild bootstrap for objects of type `fixest` and `fixest_multi` from the `fixest` package

[s3alfisc.github.io/wildrwolf/](https://s3alfisc.github.io/wildrwolf/ "https://s3alfisc.github.io/wildrwolf/")
- <https://github.com/s3alfisc/wildrwolf>

# MachineControl

### Causal inference and policy evaluation without a control group

##### *[Augusto Cerqua](https://flore.unifi.it/cris/rp/rp156520);[Marco Letta](https://flore.unifi.it/cris/rp/rp156460);[Fiammetta Menchetti](https://flore.unifi.it/cris/rp/rp08886)*


#### Abstract

Without a control group, the most widespread methodologies for estimating causal effects cannot be applied. To fill this gap, we propose the Machine Learning Control Method, a new approach for causal panel analysis that estimates causal parameters without relying on untreated units. We formalize identification within the potential outcomes framework and then provide estimation based on machine learning algorithms. To illustrate the practical relevance of our method, we present simulation evidence, a replication study, and an empirical application on the impact of the COVID-19 crisis on educational inequality. We implement the proposed approach in the companion R package MachineControl.

https://flore.unifi.it/handle/2158/1407495

- R package: `MachineControl`



# 综述：

- Arkhangelsky, D., & Imbens, G. (2024). Causal models for longitudinal and panel data: a survey. The Econometrics Journal, 27(3), C1–C61. [Link](https://doi.org/10.1093/ectj/utae014), [-PDF-](https://watermark.silverchair.com/utae014.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA2EwggNdBgkqhkiG9w0BBwagggNOMIIDSgIBADCCA0MGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMrICHONYKZauEOih9AgEQgIIDFFTpoGkt84ZKBQlGFNU_7QK0oJzFvGb2wLU2XbzOd7Z3Gei2ebqmYH-BiZKyi3NkHu3kgvHzSp16mjM_9u0n8dO9ob-gLd5zefsyZnmL_KJdlQjjzaXX1k-WHwnKKnd2Tv4VL34yszUGIXXsKqXdAVmq4ZUDK_zkoqwiqnJIIra6jh7f8K0Sx1cjxEtN8NB_bfw3oMeQKd7hDmNqU0rtTeT954VL8asI_HGWkqI1zNMicFoL2bevaoqMig9hwhc39rpX4sdEnbtl7St8joZJHyfGFx81AlhqFfrW3LEmTrN3CL3BL_gIJRpeaIZR5NBJwob6Re1lkDnmYzYi4X1ow6FRnLA2qKLnla9rma62Xp3__tRFOZmUEWXdvLgk0iKNwdx3pFP9VhMqlHSg4TD78gbvRavPgNO2X9nP0mVQ5tp9Vd7VJ3-WncPGShT3KwawA2jD7hibjji8HICJfISPdMNPnT7nPekpWTJjm1wszcQyoRyhVzaCr3AevP7xWOLJuFmQFldbGm_nAcfW5SxWL3-vNIXPQnYgAlio6tOL11W7rMUjqchc0amgPtD5URTuio5Znx6ibB0DUBsm_yL5KE5xWChCgRfaHZbPgvHLZ3yCSdV0K943N_cKouNhXbBQMb32q8k7SemARSASFBoKVuZlyXCuqitSJ2W3Vk9NxcTTVxPaftv0j4rdBe9y8NorRh0wOsJjva5nPRtacBBoLzZHrBIcMIyAEt8rVPa8W55bRzqYv6etKqj3VtOSPS29x5OFJIJ-VwqsX0B94tBY1JXiJR1oQdTyeymTHAEI6HcDME3rneYxQf2n82aMoJq99c_WVgFk1ns1YVRbsxTBhSe0a66JQG-V1LcIdyujuOvvycPBlLMRKkkVSno1z5jbZrutlDOZg7wArK-UQ5kfMf55N3jVxO74OMLCSYK6-wWqC05Ltbicx3sOsc6rrEcYPVf3mWvibGR_xGlAg6ThV2SmL-XFTeBPPD0ul80j13VddwnM6onyf0zYHmeGuYWmo1QEjWYeKbd_H3vX5COm-OyD5433), [Google](<https://scholar.google.com/scholar?q=Causal models for longitudinal and panel data: a survey>).

# 新书推荐：

- Wager, Stefan. 2024, Causal Inference: A Statistical Learning Approach. [-PDF-](https://web.stanford.edu/~swager/causal_inf_book.pdf)


# ivbounds：

Lin, A., Tommasi, D., & Zhang, L. (2024). Bounding program benefits when participation is misreported: Estimation and inference with Stata. The Stata Journal, 24(2), 185–212. [Link](https://journals.sagepub.com/doi/10.1177/1536867X241257347), [PDF](https://journals.sagepub.com/doi/pdf/10.1177/1536867X241257347), [Google](<https://scholar.google.com/scholar?q=Bounding program benefits when participation is misreported: Estimation and inference with Stata>).

- Abstract: Instrumental-variables estimation is an approach commonly used to evaluate the effect of a program in case of noncompliance. However, when the binary treatment status is misreported, standard techniques are not sufficient to point identify and consistently estimate the effect of interest. We present a new command, ivbounds, that implements three partial identification strategies developed by Tommasi and Zhang (2024, Journal of Econometrics 238: 105556) to bound the heterogeneous treatment effect when both noncompliance and misreporting of treatment status are present. We illustrate the use of the command by reassessing the benefits of participating in the 401k pension plan on savings in the United States.

## 参考文献

- Kline, B., & Tamer, E. (2023). Recent Developments in Partial Identification. Annual Review of Economics, 15(1), 125–150. [Link](https://doi.org/10.1146/annurev-economics-051520-021124), [PDF](http://sci-hub.ren/10.1146/annurev-economics-051520-021124), [Google](<https://scholar.google.com/scholar?q=Recent Developments in Partial Identification>).

# 新书推介：

**Papadopoulos, A.**, & Parmeter, C. F. (2025). Two-Tier Stochastic Frontier Analysis for the Social Sciences. Springer Nature Switzerland. [Link](https://doi.org/10.1007/978-3-031-81513-3), [PDF](https://link.springer.com/content/pdf/10.1007/978-3-031-81513-3.pdf), [Google](<https://scholar.google.com/scholar?q=Two-Tier Stochastic Frontier Analysis for the Social Sciences>), [github](https://github.com/Parms23/2TSF)

# 论文推介：双边随机边界模型
Lian, Y., Liu, C., & Parmeter, C. F. (2023). Two-tier stochastic frontier analysis using Stata. Stata Journal, 23(1), 197–229. [Link](https://doi.org/10.1177/1536867X231162033), [PDF](https://file.lianxh.cn/Refs/LianPub/Lian-2023-SJ-sftt-Two-tier-SFA.pdf), [Codes & Data](https://gitee.com/arlionn/sftt), [github](https://github.com/arlionn/sftt)

该文的相关评论，可以从如下书籍中的摘取：

**Papadopoulos, A.**, & Parmeter, C. F. (2025). Two-Tier Stochastic Frontier Analysis for the Social Sciences. Springer Nature Switzerland. [Link](https://doi.org/10.1007/978-3-031-81513-3), [PDF](https://link.springer.com/content/pdf/10.1007/978-3-031-81513-3.pdf), [Google](<https://scholar.google.com/scholar?q=Two-Tier Stochastic Frontier Analysis for the Social Sciences>), [github](https://github.com/Parms23/2TSF)

## 为何会有两个随机边界

参见 Papadopoulos & Parmeter ([2025](https://doi.org/10.1007/978-3-031-81513-3))「1.3 Why Would There Be Two Frontiers?」

## Stata 实操

```stata
ssc install sftt, replace all
```





# R 包推荐：causalQual-定性结果的因果推断

Di Francesco, R., & Mellace, G. (2025). Causal Inference for Qualitative Outcomes. arXiv. [Link](https://doi.org/10.48550/arXiv.2502.11691) (rep), [PDF](https://arxiv.org/pdf/2502.11691.pdf), [Google](<https://scholar.google.com/scholar?q=Causal Inference for Qualitative Outcomes (Version 1)>), [github](https://github.com/riccardo-df/causalQual), [Website](https://riccardo-df.github.io/causalQual/)

- 因果推断方法，如工具变量法、回归不连续性设计和差异中的差异，广泛应用于估计处理效应。然而，当这些方法用于定性结果时，会面临一些根本性挑战，因为在这种情况下，标准的因果估计量无法清晰定义。本文探讨了这些问题，并提出了一种替代框架，重点关注那些既明确又易于解释的估计量，旨在衡量处理如何影响结果类别的概率分布。我们证明了标准的识别假设足以保证因果效应的识别，并提出了简单、直观的估计策略，这些策略与传统的计量经济学方法兼容。为了便于应用，我们提供了一个开源 R 包——`causalQual`，已经在 [github](https://github.com/riccardo-df/causalQual) 上公开。

`causalQual` 包提供了一整套工具，用于在处理定性结果时估计因果效应（例如，多项选择或有序结果）。

传统的因果推断方法，如工具变量法（IV）、回归不连续性设计（RD）和倍分法（DiD），通常是为数值型结果设计的。当这些方法直接应用于定性结果时，往往会导致估计量定义不清，从而使得结果变得不明确且难以解释。

该包实现了 Di Francesco 和 Mellace（2025）提出的框架，聚焦于那些定义明确、易于解释的估计量，量化处理如何影响结果类别的概率分布。这些方法与传统的研究设计兼容，简化了应用研究者的操作过程。


Why use `causalQual`?
---------------------

| Feature                             | Benefit                                                                                                                                        |
| ----------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| **Avoids misleading conclusions**   | Conventional estimands are often undefined or depend on arbitrary outcome coding. `causalQual` targets interpretable and meaningful estimands. |
| ---                                 | ---                                                                                                                                            |
| **Provides well-defined estimands** | Instead of relying on average effects, `causalQual` models how treatment shifts probabilities over outcome categories.                         |
| **Wide applicability**              | Supports selection-on-observables, IV, RD, and DiD.                                                                                            |
| **Extensible and open-source**      | Actively developed with planned support for staggered adoption, fuzzy regression discontinuity, and more.                                      |

## R 实操

……

# 论文推介：

重点是该文的建议，即 Section 5. Recommendations for practice

Mogstad, M., & Torgovitsky, A. (2024). Instrumental variables with unobserved heterogeneity in treatment effects. Handbook of Labor Economics, 1–114. [Link](https://doi.org/10.1016/bs.heslab.2024.11.003), [PDF](http://sci-hub.ren/10.1016/bs.heslab.2024.11.003), [Google](<https://scholar.google.com/scholar?q=Instrumental variables with unobserved heterogeneity in treatment effects>). [-PDF-](https://download.ssrn.com/23/04/30/ssrn_id4433503_code1300406.pdf?response-content-disposition=inline&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCICYJHTcTQCJYYTKyveV9w3bN2kMiLV91mvUcCMmP9c8BAiBFJdsDvThtdRiAE7lnFsx5KYEv08xmCiG3VyLDpOMpqirFBQiR%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAQaDDMwODQ3NTMwMTI1NyIMWAzErqG9y2vp%2BGl%2BKpkFn%2F8UHmh%2FG8IXvZGeiuQ057T%2F%2BQGx3C6B2aHrBqjdT4ufw1QrIvgi18LSx96Ci8d5YfFmqrEZYd%2Fn8pECsie1%2BZiUyukuJcnrabQJli93AXqumWFMLy%2FPKXWSDfvgZj44O7DZjXHG5icIzKIiV3W%2FGxrl9jvBc2unIOyuj7I2KzSjlQEcEIn6R5I1XloaLICnrSCzFgu9zAWF118P5eKIGgO0wG%2FWII%2FsBBxL5%2BBBNdzPdhqYZP6NrH0ALOJKjfYn3FW5FR7MXVo%2B4GWVgSUNmp4MG52m0g7XVE%2BvR4M4bVA7uFvXsOgVCJQmvoQd2XCKVNyaN9wN6s0zGJO1gRBUUsUNy51%2FqPv54GO520ETiUF%2FILGPr8TzcYz4%2BLZEm2szzB1s3yYz9c%2FTtogxOvcs8NZwturEl6Rtb%2BvPZ%2Fu6wWqZ7jjg7Mqg1UEzUY0hlug2XrUtFDsaKEje0AIz%2FHFL1KTEr%2F8M2IOINRhrLnDtIzJWz4OLt0YecAhG1vZ92D1CiD%2B975IgpVqJbQAtgemgix%2Fu8UStWfGVLUgH4AF7btUMDJCOceQjzUO4pHwv7QtSBjbwQ9uwkslPplJqvIjCTXRK3w2ZsPjgnvzV5wr%2FoyZ0D4FIdvdgdJeIsnv%2FZ3iyYUsvF3nvTKIWlS3ho1AkHUrSV2tM5aKV2IUdRlfHue24ozNB4HtOr7SZNhhWWnajRaWQr3WEtmLvByZg634XRsnnHDgc5z0sjc3Lso3Z0uzyTeT4GmIPkQ%2FgWIGyi4r4Vs3HJKmgT9qF6pj%2FhXR6FNKY9ifeZFYUQsWQk6SAOAocdEjL0S07y8LZE6iaf%2FZjdGF8qHDJYwiuLwlT9rlVce1jcsfxUZziFCXdRmWHJpyDBkXfhYQ3S6ww1b3LwgY6sgEQww68kBbp2pKpd1ZEdDiNpDn7G1BDilpLfoSosiWwF%2FkwRYEp1Ebm%2FUlYhxMfi%2Bgl95csVgJdTUSamNNA2U56uU44qkiNcHKMuFGriwxdvOLqp4yK819FPkkWCAFg6g5itqCPd2bDo2wsfS8GmeU8JDjRB%2Bt3GGwOcDEbSIXj%2BwYSHcCukxZhnB4phW3gJk8JKcGrZbjUK1UctDqya5FmOmX2nJvZXkSr%2Bpfw9qg%2Fi2C6&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250618T164710Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAUPUUPRWE32GN6MAW%2F20250618%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=7958854f1d8456f32c82a0787161f2c6bce0a6797efa2daee54c75c0bcd73552&abstractId=4433503)


# aggTrees: Aggregation Trees

- Di Francesco, R. (2024). Aggregation Trees. arXiv. [Link](https://doi.org/10.48550/arXiv.2410.11408) (rep), [PDF](https://arxiv.org/pdf/2410.11408.pdf), [Google](<https://scholar.google.com/scholar?q=Aggregation Trees (Version 1)>), [github](), [Website](https://riccardo-df.github.io/aggTrees/), [Tutorial](https://riccardo-df.github.io/aggTrees/articles/aggTrees-vignette.html)


# valiCATE

https://riccardo-df.github.io/valiCATE/articles/valiCATE-short-tutorial.html

- 可视化：<https://riccardo-df.github.io/valiCATE/articles/more-on-plotting.html>

# 诺奖演讲推介

Angrist, J. D. (2022). Empirical Strategies in Economics: Illuminating the Path From Cause to Effect. Econometrica, 90(6), 2509–2539. [Link](https://doi.org/10.3982/ECTA20640) (rep), [PDF](http://sci-hub.ren/10.3982/ECTA20640), [Google](<https://scholar.google.com/scholar?q=Empirical Strategies in Economics: Illuminating the Path From Cause to Effect>).

# Causal ML

Zhao, Y., & Liu, Q. (2023). Causal ML: Python package for causal inference machine learning. SoftwareX, 21, 101294. [Link](https://doi.org/10.1016/j.softx.2022.101294), [PDF](http://sci-hub.ren/10.1016/j.softx.2022.101294), [Google](<https://scholar.google.com/scholar?q=Causal ML: Python package for causal inference machine learning>).

# causal-learn

翻译 + 酌情补充：

Zheng, Y., Huang, B., Chen, W., Ramsey, J., Gong, M., Cai, R., Shimizu, S., Spirtes, P., & Zhang, K. (2024). Causal-learn: Causal discovery in python. Journal of Machine Learning Research, 25(60), 1-8.


Causal Discovery in Python. It also includes (conditional) independence tests and score functions.

[causal-learn.readthedocs.io/en/latest/](https://causal-learn.readthedocs.io/en/latest/)

- [github](https://github.com/py-why/causal-learn)



# DoWhy：Python 仓库介绍

- [github](https://github.com/py-why/dowhy)

![20250619000930](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250619000930.png)

`DoWhy` is a Python library for causal inference that supports explicit modeling and testing of causal assumptions. `DoWhy` is based on a unified language for causal inference, combining causal graphical models and potential outcomes frameworks.

## [Checkout the documentation](https://py-why.github.io/dowhy/)

-   The documentation, user guide, sample notebooks and other information are available at

    [https://py-why.github.io/dowhy](https://py-why.github.io/dowhy/)

-   DoWhy is part of the [PyWhy Ecosystem](https://www.pywhy.org/). For more tools and libraries related to causality, checkout the [PyWhy GitHub organization](https://github.com/py-why/)!
-   For any questions, comments, or discussions about specific use cases, join our community on [Discord](https://discord.gg/cSBGb3vsZb) ([![discord](https://camo.githubusercontent.com/b32b103b53c60888ed9606a1ce38d9864949cb1c0a1d7c94796d7b01b6e33c99/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f383138343536383437353531313638353432)](https://discord.gg/cSBGb3vsZb))
-   Jump right into some case studies:

    -   Effect estimation: [Hotel booking cancellations](https://towardsdatascience.com/beyond-predictive-models-the-causal-story-behind-hotel-booking-cancellations-d29e8558cbaf) | [Effect of customer loyalty programs](https://www.pywhy.org/dowhy/main/example_notebooks/dowhy_example_effect_of_memberrewards_program.html) | [Optimizing article headlines](https://medium.com/@akelleh/introducing-the-do-sampler-for-causal-inference-a3296ea9e78d) | [Effect of home visits on infant health (IHDP)](https://towardsdatascience.com/implementing-causal-inference-a-key-step-towards-agi-de2cde8ea599) | [Causes of customer churn/attrition](https://medium.com/geekculture/a-quickstart-for-causal-analysis-decision-making-with-dowhy-2ce2d4d1efa9)
    -   Root cause analysis and explanations: [Causal attribution and root-cause analysis of an online shop](https://www.pywhy.org/dowhy/main/example_notebooks/gcm_online_shop.html) | [Finding the Root Cause of Elevated Latencies in a Microservice Architecture](https://www.pywhy.org/dowhy/main/example_notebooks/gcm_rca_microservice_architecture.html) | [Finding Root Causes of Changes in a Supply Chain](https://www.pywhy.org/dowhy/main/example_notebooks/gcm_supply_chain_dist_change.html)

For more example notebooks, see [here!](https://www.pywhy.org/dowhy/main/example_notebooks/nb_index.html)

# causal mediation analysis

Liu, R., Williams, N. T., Rudolph, K. E., & Díaz, I. (2024). General targeted machine learning for modern causal mediation analysis (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2408.14620) (rep), [PDF](https://arxiv.org/pdf/2408.14620.pdf), [Google](<https://scholar.google.com/scholar?q=General targeted machine learning for modern causal mediation analysis (Version 2)>).

# medoutcon

- What's medoutcon?
- [github](https://github.com/nhejazi/medoutcon)

The medoutcon R package provides facilities for efficient estimation of path-specific (in)direct effects that measure the impact of a treatment variable $A$ on an outcome variable $Y$, through a direct path (through $A$ only) and an indirect path (through a set of mediators $M$ only). In the presence of an intermediate mediator-outcome confounder $Z$, itself affected by the treatment $A$, these correspond to the interventional (in)direct effects described by Diaz et al. (2020), though similar (yet less general) effect definitions and/or estimation strategies have appeared in VanderWeele, Vansteelandt, and Robins (2014), Rudolph et al. (2017), Zheng and van der Laan (2017), and Benkeser and Ran (2021). When no intermediate confounders are present, these effect definitions simplify to the well-studied natural (in)direct effects, and our estimators are analogs of those formulated by Zheng and van der Laan (2012). Both an efficient onestep bias-corrected estimator with cross-fitting (Pfanzagl and Wefelmeyer 1985; Zheng and van der Laan 2011; Chernozhukov et al. 2018) and a cross-validated targeted minimum loss estimator (TMLE) (van der Laan and Rose 2011; Zheng and van der Laan 2011) are made available. medoutcon integrates with the sl3 R package (Coyle et al. 2021) to leverage statistical machine learning in the estimation procedure.

# 基于 DDML 的中介效应分析 - 连续变量

- Double Debiased Machine Learning for Mediation Analysis with Continuous Treatments
- [github](https://github.com/houssamzenati/double-debiased-machine-learning-mediation-continuous-treatments)

# Package ‘causalweight’
March 26, 2025

- Title: Estimation Methods for Causal Inference Based on Inverse Probability Weighting and Doubly Robust Estimation
- [-PDF-](https://cran.r-project.org/web/packages/causalweight/causalweight.pdf)

# medDML: Causal mediation analysis with double machine learning

- <>

# 论文推介：实证研究的未来和挑战

Otsuka, K., Higuchi, Y., Suzuki, A. (2024). Challenges in Empirical Research in Economics: The Way Forward. In: Otsuka, K., Kurosaki, T., Sawada, Y., Sonobe, T. (eds) Next-Generation of Empirical Research in Economics. Springer, Singapore. [-Link-](https://doi.org/10.1007/978-981-97-1887-0_4), [-PDF-](https://link.springer.com/content/pdf/10.1007/978-981-97-1887-0.pdf)



毫无疑问，随机对照试验（RCT）和自然实验（NE）作为识别因果关系的估计方法，是可靠的。在未来的经济学实证研究中，采用这些方法的研究有望占据重要位置。这些方法将占据何种重要位置，取决于它们解答的研究问题的意义。既然识别因果效应的技术已经得到建立，那么研究主题的选择将变得尤为重要。

根据作者的经验，传统的观察性研究通常按以下步骤进行：研究者从文献综述中选择看似重要的主题，进行初步调查以了解现实情况，设定研究问题，并确定分析的方向。在这一阶段，分析的最终结果尚不可知，研究主题仍有可能进行修改。因此，观察性研究允许研究者探索尚未解决的问题。然而，对于 RCT 和 NE，研究者在选题阶段就必须预测结果，因为在数据收集之前，需要考虑识别方法和 RCT 设计。如果没有选择一个合适的主题，大规模实验或大量数据收集可能会得出无意义的结果。特别是如果进行 RCT 时没有充分理解当地的实际情况，失败的风险会很高。为了避免这种情况，了解领域现实、掌握经济学理论和计量经济学技巧，对于选择一个合适的研究主题至关重要。

然而，具备所有所需技能的研究者非常少见。例如，很少有研究者能够同时掌握流行病学知识、了解非洲驱虫药物的疗效、基于经济学理论考虑外部性，并且能够运用恰当的计量经济学方法进行所有估计。因此，正如表 4.2 所示，合著者的数量正在不断增加，预计那些具备深厚领域理解、扎实经济学理论基础和计量经济学技能的研究者之间的联合研究将变得越来越重要。然而，完备的分工合作并非易事。如果不同专业背景的研究者共同合作，由于信息不对称，他们可能无法互相评估彼此的工作成果，甚至产生怀疑，这可能导致合作研究的失败。因此，只有当合著者能够理解彼此的努力和贡献时，知识共享才是联合研究成功的前提。

从这个角度来看，未来有效使用 RCT 和 NE 的门槛可能会越来越高。特别是大规模的 RCT 对于资源有限的年轻研究者来说，既昂贵又具有相当的负担。在这种情况下，使用二手数据且应用范围更广的 NE 方法可能会变得更加重要。

# 会计领域的研究中贝叶斯推断的应用
Schütt, H. H. (2023). What Can Bayesian Inference Do for Accounting Research? Journal of Financial Reporting, 8(2), 157–174. [Link](https://doi.org/10.2308/JFR-2021-002), [PDF](http://sci-hub.ren/10.2308/JFR-2021-002), [Google](<https://scholar.google.com/scholar?q=What Can Bayesian Inference Do for Accounting Research>).****


# beyond p<0.05: 

- Kallapur, Sanjay, Beyond P<0.05: Scientific Inference in Accounting Research (December 7, 2022). Studies in Accounting Research #34, American Accounting Association, Available at SSRN: https://ssrn.com/abstract=4413565 or http://dx.doi.org/10.2139/ssrn.4413565, [-PDF-](https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID4413565_code65388.pdf?abstractid=4413565&mirid=1&type=2)

## 参考文献

- Kallapur, Sanjay. 2022. *Beyond P<0.05: Scientific Inference in Accounting Research. Studies in Accounting Research*, Vol. *34*. Sarasota: American Accounting Association.[10.2139/ssrn.4413565](https://doi.org/10.2139/ssrn.4413565)[Search in Google Scholar](https://scholar.google.com/scholar?q=Kallapur%2C%20Sanjay.%202022.%20Beyond%20P%3C0.05%3A%20Scientific%20Inference%20in%20Accounting%20Research.%20Studies%20in%20Accounting%20Research%20%2C%20Vol.%C2%A0%2034%20.%20Sarasota%3A%20American%20Accounting%20Association.)

- Leuz, Christian. 2022. "Towards a Design-Based Approach to Accounting Research." *Journal of Accounting and Economics* *74* (2): 101550. <https://doi.org/10.1016/j.jacceco.2022.101550>.[Search in Google Scholar](https://scholar.google.com/scholar?q=Leuz%2C%20Christian.%202022.%20%E2%80%9CTowards%20a%20Design-Based%20Approach%20to%20Accounting%20Research.%E2%80%9D%20Journal%20of%20Accounting%20and%20Economics%2074%20%282%29%3A%20101550.%20.)
Schütt, Harm H. 2023. "What Can Bayesian Inference Do for Accounting Research?" *Journal of Financial Reporting*. August, 1--18. <https://doi.org/10.2308/JFR-2021-002>.[Search in Google Scholar](https://scholar.google.com/scholar?q=Sch%C3%BCtt%2C%20Harm%20H.%202023.%20%E2%80%9CWhat%20Can%20Bayesian%20Inference%20Do%20for%20Accounting%20Research%3F%E2%80%9D%20Journal%20of%20Financial%20Reporting%20.%20August%2C%201%E2%80%9318.%20.)


# 

Biondi, Yuri. 2025. "Limits of Empirical Studies in Accounting and Social Sciences: A Constructive Critique from Accounting, Economics and the Law." *Accounting, Economics, and Law: A Convivium* *15* (1): 9--19. <https://doi.org/10.1515/ael-2017-0026>.[Search in Google Scholar](https://scholar.google.com/scholar?q=Biondi%2C%20Yuri.%202025.%20%E2%80%9CLimits%20of%20Empirical%20Studies%20in%20Accounting%20and%20Social%20Sciences%3A%20A%20Constructive%20Critique%20from%20Accounting%2C%20Economics%20and%20the%20Law.%E2%80%9D%20Accounting%2C%20Economics%2C%20and%20Law%3A%20A%20Convivium%2015%20%281%29%3A%209%E2%80%9319.%20.)


# B862：翻译-免费在线数据库汇总

> Source: [Economic Data freely available online](https://economicsnetwork.ac.uk/links/data_free/#aea-data-links)


# B861：赵国威-v2-爬取SeekingAlpha的财报电话会议文本

- 已经提交，只是增加一个编号
- github: <https://github.com/lianxhcn/data/tree/main/conference%20call%20transcript%20sample%20data>


---



&#x1F34E; `2025/7/21 1:09`  已经发布

# B860：Stata 可视化：heatplot-热力图

写一篇推文，介绍 `heatplot` 命令的用法。主要参考资料如下：

- Ben Jann, 2019, [Heat (and hexagon) plots in Stata](https://www.stata.com/meeting/germany19/slides/germany19_Jann.pdf)

## 简介

Stata 模块 `heatplot` 用于绘制热力图和六边形热力图。

`heatplot` 可以基于变量或矩阵生成热力图。常见用法包括：将 X 和 Y 两个变量分箱后，统计每个组合出现的频率，并用颜色深浅来表示（即二维直方图）；也可以在 X 和 Y 的分箱格点上，用颜色梯度展示第三个变量 Z 的平均值，实现三元分布的可视化。此外，还可以直接用颜色梯度展示矩阵内容，比如相关系数矩阵或空间权重矩阵等。

## 安装方法

`heatplot` 是 Stata 中用于绘制热力图的强大工具。推荐通过 SSC 安装，具体步骤如下：

```stata
ssc install heatplot, replace
```

该命令依赖于 `palettes` 包（用于配色方案）以及 `colrspace` 包（Stata 14.2 及以上版本支持颜色空间管理）。请先安装这两个依赖：

```stata
ssc install palettes, replace
ssc install colrspace, replace
```

如果你希望使用 `heatplot` 的 `fast` 选项（加速大数据处理），还需安装 `gtools` 包：

```stata
ssc install gtools, replace
gtools, upgrade
```

此外，也可以直接从 GitHub 获取最新版（可能包含最新功能和修复）：

```stata
net install heatplot, replace from(https://raw.githubusercontent.com/benjann/heatplot/master/)
```

安装完成后，即可在 Stata 中使用 `heatplot` 进行热力图绘制。

## Stata 实操

> 写作说明：

执行 Ben Jann, 2019, [Heat (and hexagon) plots in Stata](https://www.stata.com/meeting/germany19/slides/germany19_Jann.pdf) 中的例子，配上说明文字。

图形模板：`set scheme cleanplots`

### 基本用法

以下是一个简单的 Stata 实操示例，演示如何使用 `heatplot` 绘制热力图：

```stata
. webuse nhanes2, clear
. heatplot weight height
``` 

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250708092845.png)

### 附加其他图形

```stata
hexplot weight height, statistic(count) color(plasma) ///
        cut(1(5)@max) keylabels(, range(1)) size ///
        addplot(lpolyci weight height, degree(1) psty(p2) lw(*1.5) ac(%50) alc(%0))
```

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250708093036.png)


# B859：cdist-如何估计反事实的分布特征？

介绍 `cdist` 命令的理论基础和应用。 
```stata
ssc install cdist, replace 
ssc install moremata, replace  // 需要利用该程序包提供的函数
net get cdist.pkg, replace //作者提供的辅助资料
```

`cdist` estimates counterfactual distributions using methods suggested by Chernozhukov et al. (2013). The unconditional (counterfactual) distributions are either obtained by distribution regression using `logit` models or by a linear quantile regression process (using `mm_qr()` from the `moremata` package).

For an alternative implementation of these (and related) methods see package [counterfactual](https://raw.githubusercontent.com/bmelly/Stata/main/) by Blaise Melly (type the following command:
```stata
net from https://raw.githubusercontent.com/bmelly/Stata/main/
```
the package also includes commands `cdeco` and `cdeco_jmp` to perform counterfactual decompositions).

## References

- Chernozhukov, Victor, Iván Fernández-Val, Blaise Melly. 2013. Inference on Counterfactual Distributions. Econometrica 81(6):2205–2268.
- Chernozhukov, Victor, Iván Fernández-Val, Blaise Melly. 2022. Fast algorithms for the quantile regression process. Empirical Economics 62(1):7–33.
- Juhn, Chinhui, Kevin M. Murphy, Brooks Pierce. 1993. Wage Inequality and the Rise in Returns to Skill. Journal of Political Economy 101(3):410-442.
- Portnoy, Stephen, Roger Koenker. 1997. The Gaussian hare and the Laplacian tortoise: computability of squared-error versus absolute-error estimators. Statistical Science 12(4):279-300.

